2019-05-10 07:24:01,715 - INFO - allennlp.common.params - random_seed = 13370
2019-05-10 07:24:01,715 - INFO - allennlp.common.params - numpy_seed = 1337
2019-05-10 07:24:01,715 - INFO - allennlp.common.params - pytorch_seed = 133
2019-05-10 07:24:02,332 - INFO - allennlp.common.checks - Pytorch version: 1.0.0
2019-05-10 07:24:02,342 - INFO - allennlp.common.params - evaluate_on_test = False
2019-05-10 07:24:02,342 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'instance_format': 'drop', 'passage_length_limit': 200, 'question_length_limit': 50, 'skip_when_all_empty': ['passage_span', 'question_span', 'addition_subtraction', 'counting'], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'drop'} and extras set()
2019-05-10 07:24:02,343 - INFO - allennlp.common.params - dataset_reader.type = drop
2019-05-10 07:24:02,343 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.reading_comprehension.drop.DropReader'> from params {'instance_format': 'drop', 'passage_length_limit': 200, 'question_length_limit': 50, 'skip_when_all_empty': ['passage_span', 'question_span', 'addition_subtraction', 'counting'], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras set()
2019-05-10 07:24:02,344 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras set()
2019-05-10 07:24:02,344 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained
2019-05-10 07:24:02,344 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'use_starting_offsets': False} and extras set()
2019-05-10 07:24:02,344 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased
2019-05-10 07:24:02,344 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False
2019-05-10 07:24:02,345 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = True
2019-05-10 07:24:02,345 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2019-05-10 07:24:02,345 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2019-05-10 07:24:02,662 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /homes/iws/patelr3/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-05-10 07:24:02,699 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'min_padding_length': 5, 'type': 'characters'} and extras set()
2019-05-10 07:24:02,699 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.type = characters
2019-05-10 07:24:02,700 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer from params {'min_padding_length': 5} and extras set()
2019-05-10 07:24:02,700 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.namespace = token_characters
2019-05-10 07:24:02,700 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.start_tokens = None
2019-05-10 07:24:02,700 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.end_tokens = None
2019-05-10 07:24:02,700 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.min_padding_length = 5
2019-05-10 07:24:02,700 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()
2019-05-10 07:24:02,700 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2019-05-10 07:24:02,700 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras set()
2019-05-10 07:24:02,700 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2019-05-10 07:24:02,700 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.lazy = False
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.passage_length_limit = 200
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.question_length_limit = 50
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.skip_when_all_empty = ['passage_span', 'question_span', 'addition_subtraction', 'counting']
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.instance_format = drop
2019-05-10 07:24:02,701 - INFO - allennlp.common.params - dataset_reader.relaxed_span_match_for_finding_labels = True
2019-05-10 07:24:02,982 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.
2019-05-10 07:24:02,982 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'instance_format': 'drop', 'passage_length_limit': 400, 'question_length_limit': 50, 'skip_when_all_empty': [], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'drop'} and extras set()
2019-05-10 07:24:02,982 - INFO - allennlp.common.params - validation_dataset_reader.type = drop
2019-05-10 07:24:02,982 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.reading_comprehension.drop.DropReader'> from params {'instance_format': 'drop', 'passage_length_limit': 400, 'question_length_limit': 50, 'skip_when_all_empty': [], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras set()
2019-05-10 07:24:02,982 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras set()
2019-05-10 07:24:02,982 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.type = bert-pretrained
2019-05-10 07:24:02,982 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'use_starting_offsets': False} and extras set()
2019-05-10 07:24:02,983 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased
2019-05-10 07:24:02,983 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.use_starting_offsets = False
2019-05-10 07:24:02,983 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.do_lowercase = True
2019-05-10 07:24:02,983 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.never_lowercase = None
2019-05-10 07:24:02,983 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.max_pieces = 512
2019-05-10 07:24:03,286 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /homes/iws/patelr3/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-05-10 07:24:03,321 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'min_padding_length': 5, 'type': 'characters'} and extras set()
2019-05-10 07:24:03,321 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.type = characters
2019-05-10 07:24:03,321 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer from params {'min_padding_length': 5} and extras set()
2019-05-10 07:24:03,321 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.namespace = token_characters
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.start_tokens = None
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.end_tokens = None
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.min_padding_length = 5
2019-05-10 07:24:03,322 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = single_id
2019-05-10 07:24:03,322 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras set()
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tokens
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.lowercase_tokens = True
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.start_tokens = None
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.end_tokens = None
2019-05-10 07:24:03,322 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False
2019-05-10 07:24:03,323 - INFO - allennlp.common.params - validation_dataset_reader.passage_length_limit = 400
2019-05-10 07:24:03,323 - INFO - allennlp.common.params - validation_dataset_reader.question_length_limit = 50
2019-05-10 07:24:03,323 - INFO - allennlp.common.params - validation_dataset_reader.skip_when_all_empty = []
2019-05-10 07:24:03,323 - INFO - allennlp.common.params - validation_dataset_reader.instance_format = drop
2019-05-10 07:24:03,323 - INFO - allennlp.common.params - validation_dataset_reader.relaxed_span_match_for_finding_labels = True
2019-05-10 07:24:03,323 - INFO - allennlp.common.params - train_data_path = drop_dataset/drop_dataset_train.json
2019-05-10 07:24:03,323 - INFO - allennlp.training.util - Reading training data from drop_dataset/drop_dataset_train.json
2019-05-10 07:24:03,324 - INFO - allennlp.data.dataset_readers.reading_comprehension.drop - Reading file at drop_dataset/drop_dataset_train.json
2019-05-10 07:24:04,117 - INFO - allennlp.data.dataset_readers.reading_comprehension.drop - Reading the dataset
2019-05-10 07:25:40,401 - INFO - allennlp.data.dataset_readers.reading_comprehension.drop - Skipped 11757 questions, kept 65652 questions.
2019-05-10 07:25:40,425 - INFO - allennlp.common.params - validation_data_path = drop_dataset/drop_dataset_dev.json
2019-05-10 07:25:40,425 - INFO - allennlp.training.util - Reading validation data from drop_dataset/drop_dataset_dev.json
2019-05-10 07:25:40,427 - INFO - allennlp.data.dataset_readers.reading_comprehension.drop - Reading file at drop_dataset/drop_dataset_dev.json
2019-05-10 07:25:40,523 - INFO - allennlp.data.dataset_readers.reading_comprehension.drop - Reading the dataset
2019-05-10 07:25:54,280 - INFO - allennlp.data.dataset_readers.reading_comprehension.drop - Skipped 0 questions, kept 9536 questions.
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - test_data_path = None
2019-05-10 07:25:54,286 - INFO - allennlp.training.trainer - From dataset instances, validation, train will be considered for vocabulary creation.
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.type = None
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.extend = False
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.directory_path = None
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = True
2019-05-10 07:25:54,286 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2019-05-10 07:25:54,286 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
0it [00:00, ?it/s]
10952it [00:10, 1095.12it/s]
21904it [00:20, 1092.50it/s]
32769it [00:30, 1087.36it/s]
43758it [00:40, 1090.77it/s]
54747it [00:50, 1087.49it/s]
65709it [01:00, 1090.05it/s]
75188it [01:10, 1071.93it/s]

2019-05-10 07:27:04,431 - INFO - allennlp.data.vocabulary - Reading pretrained tokens from: https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip
0it [00:00, ?it/s]
563227it [00:10, 56322.44it/s]
1130980it [00:20, 56457.51it/s]
1700258it [00:30, 56597.75it/s]
1702926it [00:30, 56674.18it/s]

2019-05-10 07:27:35,449 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'answering_abilities': ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting'], 'dropout_prob': 0.1, 'matrix_attention_layer': {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128, 'type': 'linear'}, 'modeling_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 6, 'num_convs_per_block': 2, 'type': 'qanet_encoder'}, 'num_highway_layers': 2, 'phrase_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4, 'type': 'qanet_encoder'}, 'regularizer': [['.*', {'alpha': 1e-07, 'type': 'l2'}]], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'}}}, 'type': 'naqanet'} and extras {'vocab'}
2019-05-10 07:27:35,450 - INFO - allennlp.common.params - model.type = naqanet
2019-05-10 07:27:35,450 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.reading_comprehension.naqanet.NumericallyAugmentedQaNet'> from params {'answering_abilities': ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting'], 'dropout_prob': 0.1, 'matrix_attention_layer': {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128, 'type': 'linear'}, 'modeling_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 6, 'num_convs_per_block': 2, 'type': 'qanet_encoder'}, 'num_highway_layers': 2, 'phrase_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4, 'type': 'qanet_encoder'}, 'regularizer': [['.*', {'alpha': 1e-07, 'type': 'l2'}]], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'}}}} and extras {'vocab'}
2019-05-10 07:27:35,451 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'}}} and extras {'vocab'}
2019-05-10 07:27:35,451 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2019-05-10 07:27:35,451 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True
2019-05-10 07:27:35,451 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'} and extras {'vocab'}
2019-05-10 07:27:35,451 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = bert-pretrained
2019-05-10 07:27:35,451 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True} and extras {'vocab'}
2019-05-10 07:27:35,451 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-uncased
2019-05-10 07:27:35,451 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = False
2019-05-10 07:27:35,451 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.top_layer_only = True
2019-05-10 07:27:35,758 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /homes/iws/patelr3/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2019-05-10 07:27:35,760 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /homes/iws/patelr3/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp8ptj4hjb
2019-05-10 07:27:38,669 - INFO - pytorch_pretrained_bert.modeling - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2019-05-10 07:27:40,363 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
2019-05-10 07:27:40,363 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 64
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
2019-05-10 07:27:40,364 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'} and extras set()
2019-05-10 07:27:40,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
2019-05-10 07:27:40,364 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200} and extras set()
2019-05-10 07:27:40,365 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 64
2019-05-10 07:27:40,365 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 200
2019-05-10 07:27:40,365 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [5]
2019-05-10 07:27:40,365 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
2019-05-10 07:27:40,367 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'} and extras {'vocab'}
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 300
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = None
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = False
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None
2019-05-10 07:27:40,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None
2019-05-10 07:27:40,368 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0
2019-05-10 07:27:40,368 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False
2019-05-10 07:27:40,368 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False
2019-05-10 07:27:40,371 - INFO - allennlp.modules.token_embedders.embedding - Reading pretrained embeddings from file
0it [00:00, ?it/s]
454466it [00:10, 45446.56it/s]
973289it [00:20, 47203.09it/s]
1523786it [00:30, 49311.69it/s]
1702926it [00:33, 51244.99it/s]

2019-05-10 07:28:13,880 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer
2019-05-10 07:28:14,231 - INFO - allennlp.modules.token_embedders.embedding - Pretrained embeddings were found for 36743 out of 36745 tokens
2019-05-10 07:28:14,240 - INFO - allennlp.common.params - model.num_highway_layers = 2
2019-05-10 07:28:14,240 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4, 'type': 'qanet_encoder'} and extras {'vocab'}
2019-05-10 07:28:14,240 - INFO - allennlp.common.params - model.phrase_layer.type = qanet_encoder
2019-05-10 07:28:14,240 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.qanet_encoder.QaNetEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4} and extras {'vocab'}
2019-05-10 07:28:14,240 - INFO - allennlp.common.params - model.phrase_layer.input_dim = 128
2019-05-10 07:28:14,240 - INFO - allennlp.common.params - model.phrase_layer.hidden_dim = 128
2019-05-10 07:28:14,240 - INFO - allennlp.common.params - model.phrase_layer.attention_projection_dim = 128
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.feedforward_hidden_dim = 128
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.num_blocks = 1
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.num_convs_per_block = 4
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.conv_kernel_size = 7
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.num_attention_heads = 8
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.use_positional_encoding = True
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.dropout_prob = 0.1
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.layer_dropout_undecayed_prob = 0.1
2019-05-10 07:28:14,241 - INFO - allennlp.common.params - model.phrase_layer.attention_dropout_prob = 0
2019-05-10 07:28:14,245 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.matrix_attention.matrix_attention.MatrixAttention'> from params {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128, 'type': 'linear'} and extras {'vocab'}
2019-05-10 07:28:14,245 - INFO - allennlp.common.params - model.matrix_attention_layer.type = linear
2019-05-10 07:28:14,245 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.matrix_attention.linear_matrix_attention.LinearMatrixAttention'> from params {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128} and extras {'vocab'}
2019-05-10 07:28:14,245 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_1_dim = 128
2019-05-10 07:28:14,245 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_2_dim = 128
2019-05-10 07:28:14,245 - INFO - allennlp.common.params - model.matrix_attention_layer.combination = x,y,x*y
2019-05-10 07:28:14,245 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 6, 'num_convs_per_block': 2, 'type': 'qanet_encoder'} and extras {'vocab'}
2019-05-10 07:28:14,245 - INFO - allennlp.common.params - model.modeling_layer.type = qanet_encoder
2019-05-10 07:28:14,245 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.qanet_encoder.QaNetEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 6, 'num_convs_per_block': 2} and extras {'vocab'}
2019-05-10 07:28:14,245 - INFO - allennlp.common.params - model.modeling_layer.input_dim = 128
2019-05-10 07:28:14,245 - INFO - allennlp.common.params - model.modeling_layer.hidden_dim = 128
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.attention_projection_dim = 128
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.feedforward_hidden_dim = 128
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.num_blocks = 6
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.num_convs_per_block = 2
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.conv_kernel_size = 5
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.num_attention_heads = 8
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.use_positional_encoding = True
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.dropout_prob = 0.1
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.layer_dropout_undecayed_prob = 0.1
2019-05-10 07:28:14,246 - INFO - allennlp.common.params - model.modeling_layer.attention_dropout_prob = 0
2019-05-10 07:28:14,260 - INFO - allennlp.common.params - model.dropout_prob = 0.1
2019-05-10 07:28:14,260 - INFO - allennlp.common.params - model.regularizer = [['.*', {'alpha': 1e-07, 'type': 'l2'}]]
2019-05-10 07:28:14,260 - INFO - allennlp.common.params - model.regularizer.0.1.type = l2
2019-05-10 07:28:14,260 - INFO - allennlp.common.params - model.answering_abilities = ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting']
2019-05-10 07:28:14,266 - INFO - allennlp.nn.initializers - Initializing parameters
2019-05-10 07:28:14,267 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _matrix_attention._bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _matrix_attention._weight_vector
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:28:14,268 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.1.bias
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.1.weight
2019-05-10 07:28:14,269 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.2.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.2.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.1.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.1.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.2.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.2.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.0.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.0.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.1.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.1.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._combined_projection.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._combined_projection.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._output_projection.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._output_projection.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_norm_layer.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_norm_layer.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward_norm_layer.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward_norm_layer.weight
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.0.1.bias
2019-05-10 07:28:14,270 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.0.1.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.0.2.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.0.2.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.1.1.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.1.1.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.1.2.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_layers.1.2.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_norm_layers.0.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_norm_layers.0.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_norm_layers.1.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2._conv_norm_layers.1.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.attention_layer._combined_projection.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.attention_layer._combined_projection.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.attention_layer._output_projection.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.attention_layer._output_projection.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.attention_norm_layer.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.attention_norm_layer.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.feedforward_norm_layer.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_2.feedforward_norm_layer.weight
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.0.1.bias
2019-05-10 07:28:14,271 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.0.1.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.0.2.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.0.2.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.1.1.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.1.1.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.1.2.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_layers.1.2.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_norm_layers.0.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_norm_layers.0.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_norm_layers.1.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3._conv_norm_layers.1.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.attention_layer._combined_projection.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.attention_layer._combined_projection.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.attention_layer._output_projection.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.attention_layer._output_projection.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.attention_norm_layer.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.attention_norm_layer.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.feedforward_norm_layer.bias
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_3.feedforward_norm_layer.weight
2019-05-10 07:28:14,272 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.0.1.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.0.1.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.0.2.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.0.2.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.1.1.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.1.1.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.1.2.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_layers.1.2.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_norm_layers.0.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_norm_layers.0.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_norm_layers.1.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4._conv_norm_layers.1.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.attention_layer._combined_projection.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.attention_layer._combined_projection.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.attention_layer._output_projection.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.attention_layer._output_projection.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.attention_norm_layer.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.attention_norm_layer.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.feedforward_norm_layer.bias
2019-05-10 07:28:14,273 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_4.feedforward_norm_layer.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.0.1.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.0.1.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.0.2.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.0.2.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.1.1.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.1.1.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.1.2.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_layers.1.2.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_norm_layers.0.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_norm_layers.0.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_norm_layers.1.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5._conv_norm_layers.1.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.attention_layer._combined_projection.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.attention_layer._combined_projection.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.attention_layer._output_projection.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.attention_layer._output_projection.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.attention_norm_layer.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.attention_norm_layer.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,274 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.feedforward_norm_layer.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_5.feedforward_norm_layer.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:28:14,275 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.1.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.1.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.2.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.2.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.1.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.1.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.2.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.2.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.2.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.2.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.3.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.3.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:28:14,276 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_weights_predictor.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _question_weights_predictor.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2019-05-10 07:28:14,277 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2019-05-10 07:28:14,278 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2019-05-10 07:28:14,279 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2019-05-10 07:28:14,280 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2019-05-10 07:28:14,281 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2019-05-10 07:28:14,282 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2019-05-10 07:28:14,283 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2019-05-10 07:28:14,284 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2019-05-10 07:28:14,285 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._embedding._module.weight
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
2019-05-10 07:28:14,286 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.weight
2019-05-10 07:28:14,380 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'max_instances_in_memory': 600, 'sorting_keys': [['passage', 'num_tokens'], ['question', 'num_tokens']], 'type': 'bucket'} and extras set()
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.type = bucket
2019-05-10 07:28:14,380 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'max_instances_in_memory': 600, 'sorting_keys': [['passage', 'num_tokens'], ['question', 'num_tokens']]} and extras set()
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.sorting_keys = [['passage', 'num_tokens'], ['question', 'num_tokens']]
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.padding_noise = 0.1
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.biggest_batch_first = False
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.batch_size = 16
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.max_instances_in_memory = 600
2019-05-10 07:28:14,380 - INFO - allennlp.common.params - iterator.cache_instances = False
2019-05-10 07:28:14,381 - INFO - allennlp.common.params - iterator.track_epoch = False
2019-05-10 07:28:14,381 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2019-05-10 07:28:14,381 - INFO - allennlp.common.params - validation_iterator = None
2019-05-10 07:28:14,381 - INFO - allennlp.common.params - trainer.no_grad = ()
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2019-05-10 07:28:14,384 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2019-05-10 07:28:14,385 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2019-05-10 07:28:14,386 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2019-05-10 07:28:14,387 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2019-05-10 07:28:14,388 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2019-05-10 07:28:14,389 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2019-05-10 07:28:14,390 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2019-05-10 07:28:14,391 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_tokens.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_token_characters._embedding._module.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _embedding_proj_layer.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _embedding_proj_layer.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _highway_layer._layers.0.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _highway_layer._layers.0.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _highway_layer._layers.1.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _highway_layer._layers.1.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _encoding_proj_layer.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _encoding_proj_layer.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.2.weight
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.2.bias
2019-05-10 07:28:14,392 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.3.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.3.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.1.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.1.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.2.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.2.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.1.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.1.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.2.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.2.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,393 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _matrix_attention._weight_vector
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _matrix_attention._bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_proj_layer.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_proj_layer.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,394 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.0.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.0.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.1.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.1.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.1.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.1.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.2.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.2.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.1.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.1.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.2.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.2.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_norm_layer.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_norm_layer.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._combined_projection.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._combined_projection.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._output_projection.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._output_projection.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward_norm_layer.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward_norm_layer.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_norm_layers.0.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_norm_layers.0.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_norm_layers.1.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_norm_layers.1.bias
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.0.1.weight
2019-05-10 07:28:14,395 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.0.1.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.0.2.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.0.2.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.1.1.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.1.1.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.1.2.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2._conv_layers.1.2.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.attention_norm_layer.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.attention_norm_layer.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.attention_layer._combined_projection.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.attention_layer._combined_projection.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.attention_layer._output_projection.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.attention_layer._output_projection.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.feedforward_norm_layer.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.feedforward_norm_layer.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_2.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_norm_layers.0.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_norm_layers.0.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_norm_layers.1.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_norm_layers.1.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.0.1.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.0.1.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.0.2.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.0.2.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.1.1.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.1.1.bias
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.1.2.weight
2019-05-10 07:28:14,396 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3._conv_layers.1.2.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.attention_norm_layer.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.attention_norm_layer.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.attention_layer._combined_projection.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.attention_layer._combined_projection.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.attention_layer._output_projection.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.attention_layer._output_projection.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.feedforward_norm_layer.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.feedforward_norm_layer.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_3.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_norm_layers.0.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_norm_layers.0.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_norm_layers.1.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_norm_layers.1.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.0.1.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.0.1.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.0.2.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.0.2.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.1.1.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.1.1.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.1.2.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4._conv_layers.1.2.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.attention_norm_layer.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.attention_norm_layer.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.attention_layer._combined_projection.weight
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.attention_layer._combined_projection.bias
2019-05-10 07:28:14,397 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.attention_layer._output_projection.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.attention_layer._output_projection.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.feedforward_norm_layer.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.feedforward_norm_layer.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_4.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_norm_layers.0.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_norm_layers.0.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_norm_layers.1.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_norm_layers.1.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.0.1.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.0.1.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.0.2.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.0.2.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.1.1.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.1.1.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.1.2.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5._conv_layers.1.2.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.attention_norm_layer.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.attention_norm_layer.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.attention_layer._combined_projection.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.attention_layer._combined_projection.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.attention_layer._output_projection.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.attention_layer._output_projection.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.feedforward_norm_layer.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.feedforward_norm_layer.bias
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.feedforward._linear_layers.0.weight
2019-05-10 07:28:14,398 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.feedforward._linear_layers.0.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.feedforward._linear_layers.1.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_5.feedforward._linear_layers.1.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_weights_predictor.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_weights_predictor.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_weights_predictor.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_weights_predictor.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.0.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.0.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.1.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.1.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.0.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.0.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.1.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.1.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.0.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.0.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.1.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.1.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.0.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.0.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.1.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.1.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.0.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.0.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.1.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.1.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.0.weight
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.0.bias
2019-05-10 07:28:14,399 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.1.weight
2019-05-10 07:28:14,400 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.1.bias
2019-05-10 07:28:14,400 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.0.weight
2019-05-10 07:28:14,400 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.0.bias
2019-05-10 07:28:14,400 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.1.weight
2019-05-10 07:28:14,400 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.1.bias
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.patience = 10
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.shuffle = True
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.num_epochs = 10
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.cuda_device = 1
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.grad_norm = 5
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.grad_clipping = None
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2019-05-10 07:28:14,400 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2019-05-10 07:28:17,091 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2019-05-10 07:28:17,091 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2019-05-10 07:28:17,091 - INFO - allennlp.training.optimizers - Number of trainable parameters: 1594464
2019-05-10 07:28:17,091 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True
2019-05-10 07:28:17,091 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-05-10 07:28:17,091 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-05-10 07:28:17,091 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.8, 0.999]
2019-05-10 07:28:17,091 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-07
2019-05-10 07:28:17,092 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0005
2019-05-10 07:28:17,092 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.moving_average.MovingAverage'> from params {'decay': 0.9999, 'type': 'exponential'} and extras {'parameters'}
2019-05-10 07:28:17,092 - INFO - allennlp.common.params - trainer.moving_average.type = exponential
2019-05-10 07:28:17,092 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.moving_average.ExponentialMovingAverage'> from params {'decay': 0.9999} and extras {'parameters'}
2019-05-10 07:28:17,092 - INFO - allennlp.common.params - trainer.moving_average.decay = 0.9999
2019-05-10 07:28:17,092 - INFO - allennlp.common.params - trainer.moving_average.numerator = 1.0
2019-05-10 07:28:17,092 - INFO - allennlp.common.params - trainer.moving_average.denominator = 10.0
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.model_save_interval = None
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.summary_interval = 100
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.histogram_interval = None
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False
2019-05-10 07:28:17,098 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2019-05-10 07:28:17,107 - INFO - allennlp.training.trainer - Beginning training.
2019-05-10 07:28:17,108 - INFO - allennlp.training.trainer - Epoch 0/9
2019-05-10 07:28:17,108 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5915.92
2019-05-10 07:28:17,235 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 10
2019-05-10 07:28:17,236 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 1181
2019-05-10 07:28:17,244 - INFO - allennlp.training.trainer - Training
  0%|          | 0/4104 [00:00<?, ?it/s]
em: 0.0395, f1: 0.0454, loss: 8.2345 ||:   0%|          | 19/4104 [00:10<37:17,  1.83it/s]
em: 0.0325, f1: 0.0429, loss: 7.6964 ||:   1%|          | 39/4104 [00:20<36:42,  1.85it/s]
em: 0.0417, f1: 0.0547, loss: 7.1323 ||:   2%|1         | 62/4104 [00:31<34:35,  1.95it/s]
em: 0.0476, f1: 0.0644, loss: 6.7814 ||:   2%|2         | 85/4104 [00:43<34:25,  1.95it/s]
em: 0.0480, f1: 0.0643, loss: 6.6076 ||:   3%|2         | 107/4104 [00:53<33:13,  2.01it/s]
em: 0.0541, f1: 0.0719, loss: 6.4737 ||:   3%|3         | 129/4104 [01:05<33:57,  1.95it/s]
em: 0.0600, f1: 0.0774, loss: 6.3447 ||:   4%|3         | 151/4104 [01:15<32:38,  2.02it/s]
em: 0.0673, f1: 0.0876, loss: 6.1745 ||:   4%|4         | 173/4104 [01:26<33:05,  1.98it/s]
em: 0.0715, f1: 0.0941, loss: 6.0499 ||:   5%|4         | 193/4104 [01:37<33:04,  1.97it/s]
em: 0.0769, f1: 0.1019, loss: 5.9230 ||:   5%|5         | 215/4104 [01:47<31:56,  2.03it/s]
em: 0.0839, f1: 0.1102, loss: 5.8086 ||:   6%|5         | 237/4104 [01:58<32:00,  2.01it/s]
em: 0.0853, f1: 0.1129, loss: 5.7490 ||:   6%|6         | 260/4104 [02:08<30:55,  2.07it/s]
em: 0.0881, f1: 0.1175, loss: 5.6897 ||:   7%|6         | 283/4104 [02:20<31:30,  2.02it/s]
em: 0.0878, f1: 0.1174, loss: 5.6561 ||:   7%|7         | 305/4104 [02:32<32:07,  1.97it/s]
em: 0.0913, f1: 0.1215, loss: 5.5972 ||:   8%|7         | 327/4104 [02:42<31:08,  2.02it/s]
em: 0.0950, f1: 0.1265, loss: 5.5430 ||:   9%|8         | 349/4104 [02:54<31:38,  1.98it/s]
em: 0.0961, f1: 0.1268, loss: 5.5202 ||:   9%|9         | 371/4104 [03:04<30:42,  2.03it/s]
em: 0.0971, f1: 0.1278, loss: 5.4803 ||:  10%|9         | 393/4104 [03:16<31:02,  1.99it/s]
em: 0.0968, f1: 0.1268, loss: 5.4687 ||:  10%|#         | 415/4104 [03:26<30:05,  2.04it/s]
em: 0.0992, f1: 0.1295, loss: 5.4266 ||:  11%|#         | 437/4104 [03:38<30:40,  1.99it/s]
em: 0.0999, f1: 0.1310, loss: 5.3924 ||:  11%|#1        | 457/4104 [03:49<31:29,  1.93it/s]
em: 0.1004, f1: 0.1314, loss: 5.3808 ||:  12%|#1        | 480/4104 [03:59<29:49,  2.03it/s]
em: 0.1022, f1: 0.1339, loss: 5.3445 ||:  12%|#2        | 503/4104 [04:11<30:26,  1.97it/s]
em: 0.1030, f1: 0.1349, loss: 5.3036 ||:  13%|#2        | 525/4104 [04:21<29:19,  2.03it/s]
em: 0.1033, f1: 0.1351, loss: 5.2775 ||:  13%|#3        | 547/4104 [04:33<29:38,  2.00it/s]
em: 0.1055, f1: 0.1374, loss: 5.2505 ||:  14%|#3        | 569/4104 [04:43<28:48,  2.05it/s]
em: 0.1069, f1: 0.1386, loss: 5.2212 ||:  14%|#4        | 591/4104 [04:58<31:59,  1.83it/s]
em: 0.1081, f1: 0.1398, loss: 5.2068 ||:  15%|#4        | 610/4104 [05:08<31:51,  1.83it/s]
em: 0.1088, f1: 0.1405, loss: 5.1866 ||:  15%|#5        | 632/4104 [05:18<30:10,  1.92it/s]
em: 0.1106, f1: 0.1425, loss: 5.1615 ||:  16%|#5        | 654/4104 [05:30<29:51,  1.93it/s]
em: 0.1113, f1: 0.1432, loss: 5.1380 ||:  16%|#6        | 677/4104 [05:40<28:28,  2.01it/s]
em: 0.1113, f1: 0.1433, loss: 5.1199 ||:  17%|#7        | 700/4104 [05:52<28:48,  1.97it/s]
em: 0.1120, f1: 0.1445, loss: 5.0951 ||:  18%|#7        | 723/4104 [06:04<28:34,  1.97it/s]
em: 0.1129, f1: 0.1451, loss: 5.0766 ||:  18%|#8        | 745/4104 [06:14<27:31,  2.03it/s]
em: 0.1135, f1: 0.1461, loss: 5.0535 ||:  19%|#8        | 767/4104 [06:25<27:54,  1.99it/s]
em: 0.1144, f1: 0.1468, loss: 5.0367 ||:  19%|#9        | 789/4104 [06:35<27:01,  2.04it/s]
em: 0.1152, f1: 0.1475, loss: 5.0229 ||:  20%|#9        | 811/4104 [06:47<27:21,  2.01it/s]
em: 0.1156, f1: 0.1484, loss: 5.0079 ||:  20%|##        | 833/4104 [06:57<26:28,  2.06it/s]
em: 0.1153, f1: 0.1480, loss: 5.0003 ||:  21%|##        | 855/4104 [07:08<26:52,  2.01it/s]
em: 0.1162, f1: 0.1490, loss: 4.9867 ||:  21%|##1       | 875/4104 [07:19<27:11,  1.98it/s]
em: 0.1171, f1: 0.1499, loss: 4.9770 ||:  22%|##1       | 896/4104 [07:29<26:33,  2.01it/s]
em: 0.1186, f1: 0.1516, loss: 4.9630 ||:  22%|##2       | 917/4104 [07:40<27:01,  1.96it/s]
em: 0.1194, f1: 0.1527, loss: 4.9398 ||:  23%|##2       | 940/4104 [07:50<25:52,  2.04it/s]
em: 0.1207, f1: 0.1539, loss: 4.9165 ||:  23%|##3       | 963/4104 [08:02<26:04,  2.01it/s]
em: 0.1218, f1: 0.1549, loss: 4.9053 ||:  24%|##4       | 985/4104 [08:12<25:13,  2.06it/s]
em: 0.1221, f1: 0.1551, loss: 4.9030 ||:  25%|##4       | 1007/4104 [08:24<25:49,  2.00it/s]
em: 0.1234, f1: 0.1563, loss: 4.8921 ||:  25%|##5       | 1027/4104 [08:34<25:49,  1.99it/s]
em: 0.1228, f1: 0.1558, loss: 4.8873 ||:  26%|##5       | 1050/4104 [08:45<24:46,  2.05it/s]
em: 0.1231, f1: 0.1562, loss: 4.8794 ||:  26%|##6       | 1073/4104 [08:57<25:21,  1.99it/s]
em: 0.1230, f1: 0.1561, loss: 4.8722 ||:  27%|##6       | 1095/4104 [09:07<24:28,  2.05it/s]
em: 0.1234, f1: 0.1566, loss: 4.8634 ||:  27%|##7       | 1117/4104 [09:19<25:06,  1.98it/s]
em: 0.1239, f1: 0.1575, loss: 4.8576 ||:  28%|##7       | 1139/4104 [09:29<24:16,  2.04it/s]
em: 0.1242, f1: 0.1576, loss: 4.8455 ||:  28%|##8       | 1161/4104 [09:40<24:25,  2.01it/s]
em: 0.1251, f1: 0.1583, loss: 4.8343 ||:  29%|##8       | 1181/4104 [09:51<24:45,  1.97it/s]
em: 0.1258, f1: 0.1589, loss: 4.8231 ||:  29%|##9       | 1203/4104 [10:01<24:03,  2.01it/s]
em: 0.1258, f1: 0.1588, loss: 4.8159 ||:  30%|##9       | 1225/4104 [10:13<24:25,  1.96it/s]
em: 0.1256, f1: 0.1585, loss: 4.8080 ||:  30%|###       | 1247/4104 [10:23<23:33,  2.02it/s]
em: 0.1263, f1: 0.1591, loss: 4.8009 ||:  31%|###       | 1269/4104 [10:35<23:52,  1.98it/s]
em: 0.1265, f1: 0.1594, loss: 4.7928 ||:  31%|###1      | 1292/4104 [10:45<22:49,  2.05it/s]
em: 0.1267, f1: 0.1598, loss: 4.7857 ||:  32%|###2      | 1315/4104 [10:57<23:10,  2.01it/s]
em: 0.1270, f1: 0.1602, loss: 4.7780 ||:  33%|###2      | 1335/4104 [11:08<23:25,  1.97it/s]
em: 0.1276, f1: 0.1608, loss: 4.7678 ||:  33%|###3      | 1357/4104 [11:18<22:35,  2.03it/s]
em: 0.1281, f1: 0.1614, loss: 4.7595 ||:  34%|###3      | 1379/4104 [11:34<25:21,  1.79it/s]
em: 0.1285, f1: 0.1618, loss: 4.7509 ||:  34%|###4      | 1400/4104 [11:44<24:05,  1.87it/s]
em: 0.1294, f1: 0.1625, loss: 4.7410 ||:  35%|###4      | 1421/4104 [11:55<24:04,  1.86it/s]
em: 0.1295, f1: 0.1630, loss: 4.7349 ||:  35%|###5      | 1443/4104 [12:05<22:53,  1.94it/s]
em: 0.1294, f1: 0.1630, loss: 4.7264 ||:  36%|###5      | 1465/4104 [12:17<22:58,  1.91it/s]
em: 0.1294, f1: 0.1629, loss: 4.7164 ||:  36%|###6      | 1484/4104 [12:27<22:58,  1.90it/s]
em: 0.1302, f1: 0.1636, loss: 4.7083 ||:  37%|###6      | 1506/4104 [12:38<22:02,  1.96it/s]
em: 0.1312, f1: 0.1643, loss: 4.7008 ||:  37%|###7      | 1528/4104 [12:49<22:01,  1.95it/s]
em: 0.1313, f1: 0.1644, loss: 4.6966 ||:  38%|###7      | 1551/4104 [13:00<21:05,  2.02it/s]
em: 0.1318, f1: 0.1647, loss: 4.6887 ||:  38%|###8      | 1573/4104 [13:11<20:57,  2.01it/s]
em: 0.1321, f1: 0.1651, loss: 4.6813 ||:  39%|###8      | 1595/4104 [13:21<20:16,  2.06it/s]
em: 0.1325, f1: 0.1655, loss: 4.6753 ||:  39%|###9      | 1617/4104 [13:33<20:45,  2.00it/s]
em: 0.1326, f1: 0.1657, loss: 4.6716 ||:  40%|###9      | 1636/4104 [13:43<21:02,  1.95it/s]
em: 0.1331, f1: 0.1662, loss: 4.6664 ||:  40%|####      | 1658/4104 [13:53<20:14,  2.01it/s]
em: 0.1334, f1: 0.1664, loss: 4.6570 ||:  41%|####      | 1680/4104 [14:04<20:15,  1.99it/s]
em: 0.1336, f1: 0.1665, loss: 4.6519 ||:  41%|####1     | 1702/4104 [14:15<19:43,  2.03it/s]
em: 0.1339, f1: 0.1666, loss: 4.6455 ||:  42%|####2     | 1724/4104 [14:26<19:45,  2.01it/s]
em: 0.1342, f1: 0.1668, loss: 4.6388 ||:  43%|####2     | 1746/4104 [14:36<19:04,  2.06it/s]
em: 0.1344, f1: 0.1670, loss: 4.6330 ||:  43%|####3     | 1768/4104 [14:47<19:12,  2.03it/s]
em: 0.1346, f1: 0.1672, loss: 4.6266 ||:  44%|####3     | 1788/4104 [14:58<19:33,  1.97it/s]
em: 0.1348, f1: 0.1676, loss: 4.6219 ||:  44%|####4     | 1810/4104 [15:08<18:51,  2.03it/s]
em: 0.1357, f1: 0.1684, loss: 4.6176 ||:  45%|####4     | 1832/4104 [15:19<18:57,  2.00it/s]
em: 0.1364, f1: 0.1692, loss: 4.6116 ||:  45%|####5     | 1855/4104 [15:30<18:05,  2.07it/s]
em: 0.1366, f1: 0.1693, loss: 4.6059 ||:  46%|####5     | 1878/4104 [15:42<18:21,  2.02it/s]
em: 0.1365, f1: 0.1692, loss: 4.6009 ||:  46%|####6     | 1900/4104 [15:52<17:47,  2.07it/s]
em: 0.1364, f1: 0.1691, loss: 4.5936 ||:  47%|####6     | 1922/4104 [16:03<18:00,  2.02it/s]
em: 0.1368, f1: 0.1695, loss: 4.5895 ||:  47%|####7     | 1942/4104 [16:14<18:20,  1.96it/s]
em: 0.1369, f1: 0.1697, loss: 4.5845 ||:  48%|####7     | 1965/4104 [16:24<17:29,  2.04it/s]
em: 0.1369, f1: 0.1699, loss: 4.5752 ||:  48%|####8     | 1988/4104 [16:36<17:42,  1.99it/s]
em: 0.1375, f1: 0.1708, loss: 4.5692 ||:  49%|####8     | 2010/4104 [16:47<17:07,  2.04it/s]
em: 0.1381, f1: 0.1714, loss: 4.5638 ||:  50%|####9     | 2032/4104 [16:58<17:16,  2.00it/s]
em: 0.1382, f1: 0.1714, loss: 4.5594 ||:  50%|#####     | 2053/4104 [17:09<17:19,  1.97it/s]
em: 0.1385, f1: 0.1717, loss: 4.5562 ||:  51%|#####     | 2075/4104 [17:19<16:36,  2.04it/s]
em: 0.1387, f1: 0.1718, loss: 4.5527 ||:  51%|#####1    | 2097/4104 [17:30<16:29,  2.03it/s]
em: 0.1393, f1: 0.1723, loss: 4.5500 ||:  52%|#####1    | 2118/4104 [17:40<16:11,  2.04it/s]
em: 0.1397, f1: 0.1727, loss: 4.5458 ||:  52%|#####2    | 2139/4104 [17:52<16:43,  1.96it/s]
em: 0.1399, f1: 0.1730, loss: 4.5380 ||:  53%|#####2    | 2161/4104 [18:02<16:00,  2.02it/s]
em: 0.1406, f1: 0.1736, loss: 4.5307 ||:  53%|#####3    | 2183/4104 [18:13<16:01,  2.00it/s]
em: 0.1407, f1: 0.1738, loss: 4.5243 ||:  54%|#####3    | 2205/4104 [18:24<15:52,  1.99it/s]
em: 0.1408, f1: 0.1740, loss: 4.5186 ||:  54%|#####4    | 2228/4104 [18:35<15:09,  2.06it/s]
em: 0.1414, f1: 0.1746, loss: 4.5124 ||:  55%|#####4    | 2251/4104 [18:46<15:14,  2.03it/s]
em: 0.1418, f1: 0.1751, loss: 4.5056 ||:  55%|#####5    | 2274/4104 [18:57<14:34,  2.09it/s]
em: 0.1420, f1: 0.1752, loss: 4.5007 ||:  56%|#####5    | 2297/4104 [19:08<14:42,  2.05it/s]
em: 0.1424, f1: 0.1756, loss: 4.4955 ||:  57%|#####6    | 2319/4104 [19:20<14:54,  2.00it/s]
em: 0.1426, f1: 0.1758, loss: 4.4895 ||:  57%|#####7    | 2342/4104 [19:30<14:14,  2.06it/s]
em: 0.1428, f1: 0.1760, loss: 4.4857 ||:  58%|#####7    | 2365/4104 [19:42<14:17,  2.03it/s]
em: 0.1434, f1: 0.1767, loss: 4.4837 ||:  58%|#####8    | 2388/4104 [19:52<13:43,  2.08it/s]
em: 0.1436, f1: 0.1770, loss: 4.4816 ||:  59%|#####8    | 2411/4104 [20:09<15:30,  1.82it/s]
em: 0.1441, f1: 0.1776, loss: 4.4780 ||:  59%|#####9    | 2433/4104 [20:20<15:04,  1.85it/s]
em: 0.1443, f1: 0.1778, loss: 4.4729 ||:  60%|#####9    | 2456/4104 [20:31<14:03,  1.95it/s]
em: 0.1444, f1: 0.1779, loss: 4.4705 ||:  60%|######    | 2479/4104 [20:42<13:40,  1.98it/s]
em: 0.1445, f1: 0.1780, loss: 4.4679 ||:  61%|######    | 2501/4104 [20:52<13:05,  2.04it/s]
em: 0.1449, f1: 0.1783, loss: 4.4645 ||:  61%|######1   | 2523/4104 [21:03<13:10,  2.00it/s]
em: 0.1455, f1: 0.1789, loss: 4.4583 ||:  62%|######2   | 2546/4104 [21:13<12:30,  2.08it/s]
em: 0.1461, f1: 0.1794, loss: 4.4519 ||:  63%|######2   | 2569/4104 [21:25<12:30,  2.05it/s]
em: 0.1466, f1: 0.1799, loss: 4.4458 ||:  63%|######3   | 2589/4104 [21:35<12:34,  2.01it/s]
em: 0.1470, f1: 0.1803, loss: 4.4449 ||:  64%|######3   | 2611/4104 [21:45<12:05,  2.06it/s]
em: 0.1474, f1: 0.1806, loss: 4.4405 ||:  64%|######4   | 2633/4104 [21:57<12:12,  2.01it/s]
em: 0.1477, f1: 0.1807, loss: 4.4361 ||:  65%|######4   | 2655/4104 [22:07<11:45,  2.05it/s]
em: 0.1481, f1: 0.1812, loss: 4.4325 ||:  65%|######5   | 2677/4104 [22:19<11:46,  2.02it/s]
em: 0.1483, f1: 0.1815, loss: 4.4279 ||:  66%|######5   | 2699/4104 [22:30<11:43,  2.00it/s]
em: 0.1482, f1: 0.1813, loss: 4.4247 ||:  66%|######6   | 2721/4104 [22:40<11:19,  2.04it/s]
em: 0.1483, f1: 0.1814, loss: 4.4239 ||:  67%|######6   | 2743/4104 [22:52<11:22,  1.99it/s]
em: 0.1483, f1: 0.1815, loss: 4.4199 ||:  67%|######7   | 2765/4104 [23:02<10:57,  2.04it/s]
em: 0.1489, f1: 0.1820, loss: 4.4168 ||:  68%|######7   | 2787/4104 [23:13<10:56,  2.01it/s]
em: 0.1489, f1: 0.1822, loss: 4.4144 ||:  68%|######8   | 2809/4104 [23:23<10:31,  2.05it/s]
em: 0.1490, f1: 0.1822, loss: 4.4125 ||:  69%|######8   | 2831/4104 [23:35<10:28,  2.02it/s]
em: 0.1493, f1: 0.1826, loss: 4.4088 ||:  69%|######9   | 2851/4104 [23:45<10:33,  1.98it/s]
em: 0.1498, f1: 0.1831, loss: 4.4076 ||:  70%|#######   | 2873/4104 [23:56<10:08,  2.02it/s]
em: 0.1500, f1: 0.1834, loss: 4.4052 ||:  71%|#######   | 2895/4104 [24:07<10:08,  1.99it/s]
em: 0.1502, f1: 0.1835, loss: 4.4050 ||:  71%|#######1  | 2917/4104 [24:17<09:40,  2.05it/s]
em: 0.1506, f1: 0.1837, loss: 4.4023 ||:  72%|#######1  | 2939/4104 [24:29<09:42,  2.00it/s]
em: 0.1511, f1: 0.1842, loss: 4.4020 ||:  72%|#######2  | 2961/4104 [24:39<09:18,  2.05it/s]
em: 0.1510, f1: 0.1841, loss: 4.4005 ||:  73%|#######2  | 2983/4104 [24:50<09:20,  2.00it/s]
em: 0.1510, f1: 0.1841, loss: 4.4006 ||:  73%|#######3  | 3003/4104 [25:01<09:22,  1.96it/s]
em: 0.1513, f1: 0.1843, loss: 4.3962 ||:  74%|#######3  | 3026/4104 [25:12<08:50,  2.03it/s]
em: 0.1517, f1: 0.1846, loss: 4.3908 ||:  74%|#######4  | 3049/4104 [25:23<08:47,  2.00it/s]
em: 0.1519, f1: 0.1848, loss: 4.3864 ||:  75%|#######4  | 3071/4104 [25:34<08:23,  2.05it/s]
em: 0.1520, f1: 0.1850, loss: 4.3816 ||:  75%|#######5  | 3093/4104 [25:45<08:23,  2.01it/s]
em: 0.1523, f1: 0.1854, loss: 4.3788 ||:  76%|#######5  | 3115/4104 [25:55<08:01,  2.05it/s]
em: 0.1524, f1: 0.1854, loss: 4.3760 ||:  76%|#######6  | 3137/4104 [26:07<08:02,  2.00it/s]
em: 0.1525, f1: 0.1854, loss: 4.3743 ||:  77%|#######6  | 3156/4104 [26:17<08:01,  1.97it/s]
em: 0.1527, f1: 0.1856, loss: 4.3701 ||:  77%|#######7  | 3178/4104 [26:27<07:35,  2.03it/s]
em: 0.1531, f1: 0.1861, loss: 4.3650 ||:  78%|#######7  | 3200/4104 [26:38<07:32,  2.00it/s]
em: 0.1534, f1: 0.1863, loss: 4.3611 ||:  79%|#######8  | 3223/4104 [26:48<07:05,  2.07it/s]
em: 0.1535, f1: 0.1864, loss: 4.3575 ||:  79%|#######9  | 3246/4104 [27:00<07:01,  2.03it/s]
em: 0.1539, f1: 0.1868, loss: 4.3536 ||:  80%|#######9  | 3269/4104 [27:12<06:55,  2.01it/s]
em: 0.1539, f1: 0.1869, loss: 4.3499 ||:  80%|########  | 3292/4104 [27:22<06:33,  2.06it/s]
em: 0.1540, f1: 0.1870, loss: 4.3465 ||:  81%|########  | 3314/4104 [27:34<06:32,  2.02it/s]
em: 0.1543, f1: 0.1872, loss: 4.3408 ||:  81%|########1 | 3337/4104 [27:44<06:09,  2.08it/s]
em: 0.1545, f1: 0.1873, loss: 4.3393 ||:  82%|########1 | 3360/4104 [27:56<06:08,  2.02it/s]
em: 0.1548, f1: 0.1877, loss: 4.3359 ||:  82%|########2 | 3383/4104 [28:08<05:59,  2.01it/s]
em: 0.1550, f1: 0.1879, loss: 4.3336 ||:  83%|########2 | 3404/4104 [28:18<05:44,  2.03it/s]
em: 0.1553, f1: 0.1882, loss: 4.3324 ||:  83%|########3 | 3425/4104 [28:29<05:40,  2.00it/s]
em: 0.1554, f1: 0.1883, loss: 4.3297 ||:  84%|########3 | 3447/4104 [28:39<05:23,  2.03it/s]
em: 0.1556, f1: 0.1885, loss: 4.3267 ||:  85%|########4 | 3469/4104 [28:51<05:19,  1.99it/s]
em: 0.1559, f1: 0.1889, loss: 4.3236 ||:  85%|########5 | 3492/4104 [29:01<04:56,  2.06it/s]
em: 0.1562, f1: 0.1893, loss: 4.3227 ||:  86%|########5 | 3515/4104 [29:13<04:53,  2.00it/s]
em: 0.1563, f1: 0.1894, loss: 4.3201 ||:  86%|########6 | 3535/4104 [29:24<04:47,  1.98it/s]
em: 0.1563, f1: 0.1894, loss: 4.3191 ||:  87%|########6 | 3557/4104 [29:34<04:29,  2.03it/s]
em: 0.1564, f1: 0.1894, loss: 4.3169 ||:  87%|########7 | 3579/4104 [29:45<04:22,  2.00it/s]
em: 0.1566, f1: 0.1897, loss: 4.3150 ||:  88%|########7 | 3602/4104 [29:56<04:03,  2.06it/s]
em: 0.1569, f1: 0.1899, loss: 4.3127 ||:  88%|########8 | 3625/4104 [30:08<03:57,  2.02it/s]
em: 0.1569, f1: 0.1900, loss: 4.3094 ||:  89%|########8 | 3647/4104 [30:18<03:41,  2.06it/s]
em: 0.1571, f1: 0.1902, loss: 4.3050 ||:  89%|########9 | 3669/4104 [30:29<03:34,  2.03it/s]
em: 0.1572, f1: 0.1902, loss: 4.3019 ||:  90%|########9 | 3689/4104 [30:44<03:57,  1.75it/s]
em: 0.1573, f1: 0.1902, loss: 4.3012 ||:  90%|######### | 3711/4104 [30:54<03:32,  1.85it/s]
em: 0.1574, f1: 0.1903, loss: 4.2995 ||:  91%|######### | 3733/4104 [31:06<03:19,  1.86it/s]
em: 0.1578, f1: 0.1907, loss: 4.2963 ||:  91%|#########1| 3755/4104 [31:16<03:00,  1.94it/s]
em: 0.1580, f1: 0.1908, loss: 4.2946 ||:  92%|#########2| 3777/4104 [31:28<02:50,  1.92it/s]
em: 0.1582, f1: 0.1910, loss: 4.2944 ||:  93%|#########2| 3799/4104 [31:38<02:33,  1.99it/s]
em: 0.1582, f1: 0.1910, loss: 4.2940 ||:  93%|#########3| 3821/4104 [31:50<02:24,  1.96it/s]
em: 0.1585, f1: 0.1914, loss: 4.2916 ||:  94%|#########3| 3840/4104 [32:00<02:17,  1.92it/s]
em: 0.1584, f1: 0.1913, loss: 4.2923 ||:  94%|#########4| 3862/4104 [32:11<02:02,  1.98it/s]
em: 0.1583, f1: 0.1913, loss: 4.2929 ||:  95%|#########4| 3884/4104 [32:22<01:51,  1.97it/s]
em: 0.1584, f1: 0.1915, loss: 4.2959 ||:  95%|#########5| 3906/4104 [32:32<01:37,  2.02it/s]
em: 0.1585, f1: 0.1916, loss: 4.2966 ||:  96%|#########5| 3928/4104 [32:43<01:27,  2.01it/s]
em: 0.1584, f1: 0.1916, loss: 4.2981 ||:  96%|#########6| 3950/4104 [32:53<01:15,  2.05it/s]
em: 0.1583, f1: 0.1916, loss: 4.3005 ||:  97%|#########6| 3972/4104 [33:05<01:05,  2.01it/s]
em: 0.1582, f1: 0.1915, loss: 4.3014 ||:  97%|#########7| 3992/4104 [33:15<00:56,  1.98it/s]
em: 0.1582, f1: 0.1916, loss: 4.3013 ||:  98%|#########7| 4014/4104 [33:26<00:44,  2.02it/s]
em: 0.1581, f1: 0.1915, loss: 4.3038 ||:  98%|#########8| 4036/4104 [33:37<00:33,  2.00it/s]
em: 0.1578, f1: 0.1913, loss: 4.3068 ||:  99%|#########8| 4058/4104 [33:47<00:22,  2.05it/s]
em: 0.1579, f1: 0.1914, loss: 4.3071 ||:  99%|#########9| 4080/4104 [33:58<00:11,  2.02it/s]
em: 0.1579, f1: 0.1915, loss: 4.3070 ||: 100%|#########9| 4102/4104 [34:08<00:00,  2.06it/s]
em: 0.1578, f1: 0.1913, loss: 4.3083 ||: : 4124it [34:20,  1.99it/s]                        
em: 0.1575, f1: 0.1912, loss: 4.3105 ||: : 4145it [34:30,  2.02it/s]
em: 0.1573, f1: 0.1910, loss: 4.3112 ||: : 4158it [34:36,  2.00it/s]

2019-05-10 08:02:53,850 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/596 [00:00<?, ?it/s]
em: 0.2996, f1: 0.3256, loss: 974267.4776 ||:   6%|5         | 34/596 [00:10<02:50,  3.30it/s]
em: 0.2669, f1: 0.2927, loss: 1399256.4598 ||:  11%|#1        | 67/596 [00:21<02:45,  3.19it/s]
em: 0.2526, f1: 0.2806, loss: 1617270.6769 ||:  16%|#6        | 97/596 [00:31<02:39,  3.13it/s]
em: 0.2570, f1: 0.2877, loss: 1712601.0482 ||:  21%|##1       | 127/596 [00:41<02:32,  3.08it/s]
em: 0.2488, f1: 0.2795, loss: 1648091.9077 ||:  26%|##6       | 157/596 [00:52<02:28,  2.95it/s]
em: 0.2430, f1: 0.2729, loss: 1651318.5073 ||:  32%|###1      | 190/596 [01:02<02:13,  3.05it/s]
em: 0.2350, f1: 0.2659, loss: 1615516.1431 ||:  38%|###7      | 224/596 [01:12<01:59,  3.12it/s]
em: 0.2382, f1: 0.2696, loss: 1579460.1699 ||:  43%|####3     | 258/596 [01:23<01:48,  3.12it/s]
em: 0.2367, f1: 0.2677, loss: 1568968.3375 ||:  49%|####8     | 290/596 [01:34<01:38,  3.10it/s]
em: 0.2349, f1: 0.2642, loss: 1611027.6639 ||:  54%|#####4    | 322/596 [01:44<01:28,  3.10it/s]
em: 0.2334, f1: 0.2624, loss: 1603110.1911 ||:  59%|#####9    | 354/596 [01:56<01:21,  2.99it/s]
em: 0.2367, f1: 0.2655, loss: 1533052.6106 ||:  64%|######4   | 382/596 [02:07<01:15,  2.85it/s]
em: 0.2352, f1: 0.2632, loss: 1533415.7764 ||:  70%|#######   | 419/596 [02:19<01:00,  2.93it/s]
em: 0.2322, f1: 0.2612, loss: 1507436.8561 ||:  76%|#######6  | 454/596 [02:29<00:46,  3.04it/s]
em: 0.2231, f1: 0.2519, loss: 1710797.1275 ||:  82%|########2 | 491/596 [02:39<00:32,  3.20it/s]
em: 0.2200, f1: 0.2491, loss: 1830275.8346 ||:  89%|########9 | 531/596 [02:49<00:19,  3.38it/s]
em: 0.2127, f1: 0.2420, loss: 1926537.8340 ||:  96%|#########5| 570/596 [03:01<00:07,  3.40it/s]
em: 0.2068, f1: 0.2365, loss: 1969166.6516 ||: : 604it [03:13,  3.13it/s]                       

2019-05-10 08:06:06,900 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2019-05-10 08:06:06,900 - INFO - allennlp.training.tensorboard_writer - em              |     0.157  |     0.207
2019-05-10 08:06:06,901 - INFO - allennlp.training.tensorboard_writer - gpu_1_memory_MB |  1181.000  |       N/A
2019-05-10 08:06:06,901 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5915.920  |       N/A
2019-05-10 08:06:06,901 - INFO - allennlp.training.tensorboard_writer - f1              |     0.191  |     0.236
2019-05-10 08:06:06,901 - INFO - allennlp.training.tensorboard_writer - loss            |     4.311  |  1969166.652
2019-05-10 08:06:06,901 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |    10.000  |       N/A
2019-05-10 08:06:11,946 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'out/baseline_bert/best.th'.
2019-05-10 08:06:17,139 - INFO - allennlp.training.trainer - Epoch duration: 00:38:00
2019-05-10 08:06:17,140 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:42:00
2019-05-10 08:06:17,140 - INFO - allennlp.training.trainer - Epoch 1/9
2019-05-10 08:06:17,140 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8361.796
2019-05-10 08:06:17,328 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 155
2019-05-10 08:06:17,329 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 6009
2019-05-10 08:06:17,337 - INFO - allennlp.training.trainer - Training
  0%|          | 0/4104 [00:00<?, ?it/s]
em: 0.2017, f1: 0.2217, loss: 3.6243 ||:   1%|          | 22/4104 [00:10<32:18,  2.11it/s]
em: 0.2083, f1: 0.2352, loss: 3.5914 ||:   1%|1         | 44/4104 [00:21<32:21,  2.09it/s]
em: 0.1941, f1: 0.2238, loss: 3.6650 ||:   2%|1         | 67/4104 [00:31<31:38,  2.13it/s]
em: 0.2037, f1: 0.2347, loss: 3.6826 ||:   2%|2         | 90/4104 [00:42<31:22,  2.13it/s]
em: 0.1980, f1: 0.2277, loss: 3.8002 ||:   3%|2         | 112/4104 [00:52<31:09,  2.14it/s]
em: 0.1943, f1: 0.2232, loss: 3.8140 ||:   3%|3         | 134/4104 [01:02<31:04,  2.13it/s]
em: 0.1976, f1: 0.2271, loss: 3.8055 ||:   4%|3         | 156/4104 [01:13<31:08,  2.11it/s]
em: 0.1998, f1: 0.2305, loss: 3.7807 ||:   4%|4         | 178/4104 [01:23<30:39,  2.13it/s]
em: 0.2037, f1: 0.2347, loss: 3.7445 ||:   5%|4         | 200/4104 [01:33<30:25,  2.14it/s]
em: 0.2055, f1: 0.2379, loss: 3.7261 ||:   5%|5         | 222/4104 [01:43<30:02,  2.15it/s]
em: 0.2079, f1: 0.2407, loss: 3.7341 ||:   6%|5         | 244/4104 [01:54<29:56,  2.15it/s]
em: 0.2092, f1: 0.2424, loss: 3.7318 ||:   7%|6         | 267/4104 [02:04<29:42,  2.15it/s]
em: 0.2047, f1: 0.2386, loss: 3.7693 ||:   7%|7         | 289/4104 [02:15<29:33,  2.15it/s]
em: 0.2058, f1: 0.2402, loss: 3.7687 ||:   8%|7         | 311/4104 [02:25<29:34,  2.14it/s]
em: 0.2091, f1: 0.2442, loss: 3.7552 ||:   8%|8         | 333/4104 [02:36<29:37,  2.12it/s]
em: 0.2092, f1: 0.2443, loss: 3.7697 ||:   9%|8         | 354/4104 [02:46<29:50,  2.09it/s]
em: 0.2060, f1: 0.2416, loss: 3.7716 ||:   9%|9         | 376/4104 [02:56<29:22,  2.12it/s]
em: 0.2042, f1: 0.2392, loss: 3.7738 ||:  10%|9         | 398/4104 [03:06<29:13,  2.11it/s]
em: 0.2028, f1: 0.2378, loss: 3.7837 ||:  10%|#         | 420/4104 [03:17<28:54,  2.12it/s]
em: 0.2024, f1: 0.2371, loss: 3.7737 ||:  11%|#         | 442/4104 [03:27<28:50,  2.12it/s]
em: 0.2028, f1: 0.2380, loss: 3.7741 ||:  11%|#1        | 464/4104 [03:37<28:30,  2.13it/s]
em: 0.2027, f1: 0.2376, loss: 3.7783 ||:  12%|#1        | 487/4104 [03:48<27:58,  2.16it/s]
em: 0.2025, f1: 0.2378, loss: 3.7683 ||:  12%|#2        | 510/4104 [03:59<28:02,  2.14it/s]
em: 0.2029, f1: 0.2379, loss: 3.7492 ||:  13%|#2        | 532/4104 [04:09<27:43,  2.15it/s]
em: 0.2033, f1: 0.2384, loss: 3.7487 ||:  13%|#3        | 554/4104 [04:19<27:47,  2.13it/s]
em: 0.2042, f1: 0.2396, loss: 3.7416 ||:  14%|#4        | 576/4104 [04:30<27:42,  2.12it/s]
em: 0.2059, f1: 0.2414, loss: 3.7351 ||:  15%|#4        | 598/4104 [04:40<27:29,  2.13it/s]
em: 0.2062, f1: 0.2419, loss: 3.7248 ||:  15%|#5        | 620/4104 [04:50<27:10,  2.14it/s]
em: 0.2070, f1: 0.2426, loss: 3.7294 ||:  16%|#5        | 642/4104 [05:01<27:01,  2.13it/s]
em: 0.2067, f1: 0.2424, loss: 3.7256 ||:  16%|#6        | 664/4104 [05:11<26:57,  2.13it/s]
em: 0.2073, f1: 0.2426, loss: 3.7115 ||:  17%|#6        | 686/4104 [05:21<26:31,  2.15it/s]
em: 0.2076, f1: 0.2432, loss: 3.7156 ||:  17%|#7        | 708/4104 [05:31<26:11,  2.16it/s]
em: 0.2074, f1: 0.2432, loss: 3.7114 ||:  18%|#7        | 730/4104 [05:41<26:02,  2.16it/s]
em: 0.2084, f1: 0.2440, loss: 3.7044 ||:  18%|#8        | 752/4104 [05:52<25:57,  2.15it/s]
em: 0.2079, f1: 0.2440, loss: 3.7001 ||:  19%|#8        | 774/4104 [06:02<25:55,  2.14it/s]
em: 0.2078, f1: 0.2438, loss: 3.6946 ||:  19%|#9        | 796/4104 [06:12<25:41,  2.15it/s]
em: 0.2077, f1: 0.2438, loss: 3.6975 ||:  20%|#9        | 818/4104 [06:22<25:21,  2.16it/s]
em: 0.2076, f1: 0.2439, loss: 3.7036 ||:  20%|##        | 840/4104 [06:32<25:07,  2.16it/s]
em: 0.2080, f1: 0.2444, loss: 3.7005 ||:  21%|##1       | 862/4104 [06:43<24:58,  2.16it/s]
em: 0.2069, f1: 0.2433, loss: 3.7098 ||:  22%|##1       | 884/4104 [06:53<25:11,  2.13it/s]
em: 0.2067, f1: 0.2434, loss: 3.7104 ||:  22%|##2       | 906/4104 [07:03<24:57,  2.14it/s]
em: 0.2075, f1: 0.2444, loss: 3.7023 ||:  23%|##2       | 928/4104 [07:13<24:34,  2.15it/s]
em: 0.2083, f1: 0.2450, loss: 3.6948 ||:  23%|##3       | 950/4104 [07:24<24:24,  2.15it/s]
em: 0.2081, f1: 0.2448, loss: 3.6971 ||:  24%|##3       | 972/4104 [07:34<24:20,  2.14it/s]
em: 0.2088, f1: 0.2452, loss: 3.6898 ||:  24%|##4       | 994/4104 [07:44<24:08,  2.15it/s]
em: 0.2092, f1: 0.2455, loss: 3.6949 ||:  25%|##4       | 1017/4104 [07:55<23:45,  2.16it/s]
em: 0.2091, f1: 0.2453, loss: 3.6982 ||:  25%|##5       | 1040/4104 [08:05<23:35,  2.16it/s]
em: 0.2093, f1: 0.2455, loss: 3.7002 ||:  26%|##5       | 1062/4104 [08:16<23:26,  2.16it/s]
em: 0.2095, f1: 0.2458, loss: 3.7039 ||:  26%|##6       | 1084/4104 [08:26<23:27,  2.15it/s]
em: 0.2088, f1: 0.2450, loss: 3.7042 ||:  27%|##6       | 1106/4104 [08:36<23:27,  2.13it/s]
em: 0.2082, f1: 0.2448, loss: 3.7060 ||:  27%|##7       | 1128/4104 [08:47<23:14,  2.13it/s]
em: 0.2084, f1: 0.2448, loss: 3.7055 ||:  28%|##8       | 1150/4104 [08:57<23:07,  2.13it/s]
em: 0.2084, f1: 0.2448, loss: 3.7032 ||:  29%|##8       | 1172/4104 [09:07<22:45,  2.15it/s]
em: 0.2085, f1: 0.2449, loss: 3.7014 ||:  29%|##9       | 1194/4104 [09:18<22:42,  2.14it/s]
em: 0.2093, f1: 0.2457, loss: 3.7004 ||:  30%|##9       | 1216/4104 [09:28<22:28,  2.14it/s]
em: 0.2092, f1: 0.2455, loss: 3.7006 ||:  30%|###       | 1238/4104 [09:38<22:22,  2.14it/s]
em: 0.2093, f1: 0.2455, loss: 3.6990 ||:  31%|###       | 1260/4104 [09:49<22:22,  2.12it/s]
em: 0.2099, f1: 0.2461, loss: 3.6981 ||:  31%|###1      | 1283/4104 [09:59<21:53,  2.15it/s]
em: 0.2098, f1: 0.2461, loss: 3.6978 ||:  32%|###1      | 1306/4104 [10:10<21:41,  2.15it/s]
em: 0.2102, f1: 0.2466, loss: 3.6975 ||:  32%|###2      | 1329/4104 [10:20<21:18,  2.17it/s]
em: 0.2102, f1: 0.2466, loss: 3.6960 ||:  33%|###2      | 1352/4104 [10:31<21:23,  2.14it/s]
em: 0.2100, f1: 0.2464, loss: 3.6982 ||:  33%|###3      | 1374/4104 [10:41<21:12,  2.15it/s]
em: 0.2109, f1: 0.2472, loss: 3.6948 ||:  34%|###4      | 1396/4104 [10:52<21:14,  2.12it/s]
em: 0.2109, f1: 0.2474, loss: 3.6977 ||:  35%|###4      | 1418/4104 [11:02<21:04,  2.12it/s]
em: 0.2113, f1: 0.2477, loss: 3.6919 ||:  35%|###5      | 1440/4104 [11:13<21:01,  2.11it/s]
em: 0.2113, f1: 0.2477, loss: 3.6902 ||:  36%|###5      | 1461/4104 [11:23<21:00,  2.10it/s]
em: 0.2111, f1: 0.2473, loss: 3.6876 ||:  36%|###6      | 1483/4104 [11:34<20:53,  2.09it/s]
em: 0.2105, f1: 0.2467, loss: 3.6849 ||:  37%|###6      | 1505/4104 [11:44<20:34,  2.11it/s]
em: 0.2106, f1: 0.2467, loss: 3.6825 ||:  37%|###7      | 1527/4104 [11:54<20:11,  2.13it/s]
em: 0.2100, f1: 0.2459, loss: 3.6841 ||:  38%|###7      | 1549/4104 [12:04<20:00,  2.13it/s]
em: 0.2103, f1: 0.2463, loss: 3.6816 ||:  38%|###8      | 1572/4104 [12:15<19:34,  2.16it/s]
em: 0.2105, f1: 0.2464, loss: 3.6806 ||:  39%|###8      | 1595/4104 [12:25<19:15,  2.17it/s]
em: 0.2104, f1: 0.2463, loss: 3.6822 ||:  39%|###9      | 1618/4104 [12:36<19:12,  2.16it/s]
em: 0.2102, f1: 0.2461, loss: 3.6838 ||:  40%|###9      | 1640/4104 [12:46<19:00,  2.16it/s]
em: 0.2107, f1: 0.2464, loss: 3.6827 ||:  40%|####      | 1662/4104 [12:56<18:55,  2.15it/s]
em: 0.2107, f1: 0.2465, loss: 3.6803 ||:  41%|####1     | 1684/4104 [13:07<18:43,  2.15it/s]
em: 0.2111, f1: 0.2468, loss: 3.6788 ||:  42%|####1     | 1706/4104 [13:17<18:33,  2.15it/s]
em: 0.2107, f1: 0.2463, loss: 3.6808 ||:  42%|####2     | 1728/4104 [13:27<18:25,  2.15it/s]
em: 0.2107, f1: 0.2464, loss: 3.6778 ||:  43%|####2     | 1750/4104 [13:37<18:13,  2.15it/s]
em: 0.2106, f1: 0.2463, loss: 3.6777 ||:  43%|####3     | 1772/4104 [13:48<18:00,  2.16it/s]
em: 0.2108, f1: 0.2465, loss: 3.6744 ||:  44%|####3     | 1794/4104 [13:58<17:57,  2.14it/s]
em: 0.2108, f1: 0.2466, loss: 3.6724 ||:  44%|####4     | 1816/4104 [14:08<17:41,  2.16it/s]
em: 0.2112, f1: 0.2469, loss: 3.6705 ||:  45%|####4     | 1838/4104 [14:18<17:33,  2.15it/s]
em: 0.2115, f1: 0.2472, loss: 3.6706 ||:  45%|####5     | 1860/4104 [14:28<17:17,  2.16it/s]
em: 0.2113, f1: 0.2470, loss: 3.6699 ||:  46%|####5     | 1882/4104 [14:39<17:17,  2.14it/s]
em: 0.2113, f1: 0.2470, loss: 3.6699 ||:  46%|####6     | 1904/4104 [14:49<17:06,  2.14it/s]
em: 0.2117, f1: 0.2472, loss: 3.6655 ||:  47%|####6     | 1926/4104 [14:59<16:51,  2.15it/s]
em: 0.2116, f1: 0.2472, loss: 3.6644 ||:  47%|####7     | 1948/4104 [15:10<16:51,  2.13it/s]
em: 0.2115, f1: 0.2472, loss: 3.6639 ||:  48%|####8     | 1970/4104 [15:20<16:36,  2.14it/s]
em: 0.2115, f1: 0.2470, loss: 3.6647 ||:  49%|####8     | 1992/4104 [15:31<16:37,  2.12it/s]
em: 0.2115, f1: 0.2472, loss: 3.6601 ||:  49%|####9     | 2014/4104 [15:41<16:20,  2.13it/s]
em: 0.2120, f1: 0.2477, loss: 3.6596 ||:  50%|####9     | 2036/4104 [15:51<16:04,  2.14it/s]
em: 0.2122, f1: 0.2480, loss: 3.6583 ||:  50%|#####     | 2058/4104 [16:02<16:08,  2.11it/s]
em: 0.2125, f1: 0.2482, loss: 3.6576 ||:  51%|#####     | 2080/4104 [16:12<15:46,  2.14it/s]
em: 0.2127, f1: 0.2484, loss: 3.6574 ||:  51%|#####1    | 2102/4104 [16:22<15:37,  2.14it/s]
em: 0.2127, f1: 0.2482, loss: 3.6589 ||:  52%|#####1    | 2124/4104 [16:32<15:26,  2.14it/s]
em: 0.2128, f1: 0.2484, loss: 3.6584 ||:  52%|#####2    | 2146/4104 [16:43<15:25,  2.11it/s]
em: 0.2129, f1: 0.2486, loss: 3.6551 ||:  53%|#####2    | 2167/4104 [16:53<15:31,  2.08it/s]
em: 0.2133, f1: 0.2491, loss: 3.6532 ||:  53%|#####3    | 2190/4104 [17:04<15:03,  2.12it/s]
em: 0.2136, f1: 0.2493, loss: 3.6477 ||:  54%|#####3    | 2213/4104 [17:14<14:41,  2.15it/s]
em: 0.2138, f1: 0.2495, loss: 3.6441 ||:  54%|#####4    | 2236/4104 [17:25<14:23,  2.16it/s]
em: 0.2137, f1: 0.2495, loss: 3.6426 ||:  55%|#####5    | 2259/4104 [17:36<14:29,  2.12it/s]
em: 0.2138, f1: 0.2498, loss: 3.6419 ||:  56%|#####5    | 2281/4104 [17:46<14:16,  2.13it/s]
em: 0.2135, f1: 0.2495, loss: 3.6416 ||:  56%|#####6    | 2303/4104 [17:56<14:04,  2.13it/s]
em: 0.2134, f1: 0.2494, loss: 3.6390 ||:  57%|#####6    | 2325/4104 [18:07<13:55,  2.13it/s]
em: 0.2130, f1: 0.2490, loss: 3.6379 ||:  57%|#####7    | 2347/4104 [18:17<13:46,  2.13it/s]
em: 0.2128, f1: 0.2489, loss: 3.6359 ||:  58%|#####7    | 2369/4104 [18:27<13:33,  2.13it/s]
em: 0.2130, f1: 0.2490, loss: 3.6380 ||:  58%|#####8    | 2391/4104 [18:38<13:17,  2.15it/s]
em: 0.2132, f1: 0.2493, loss: 3.6400 ||:  59%|#####8    | 2413/4104 [18:48<13:16,  2.12it/s]
em: 0.2135, f1: 0.2497, loss: 3.6396 ||:  59%|#####9    | 2434/4104 [18:58<13:13,  2.11it/s]
em: 0.2138, f1: 0.2499, loss: 3.6373 ||:  60%|#####9    | 2456/4104 [19:08<12:55,  2.13it/s]
em: 0.2140, f1: 0.2501, loss: 3.6357 ||:  60%|######    | 2478/4104 [19:18<12:37,  2.15it/s]
em: 0.2138, f1: 0.2499, loss: 3.6360 ||:  61%|######    | 2500/4104 [19:29<12:25,  2.15it/s]
em: 0.2140, f1: 0.2501, loss: 3.6356 ||:  61%|######1   | 2522/4104 [19:39<12:18,  2.14it/s]
em: 0.2144, f1: 0.2505, loss: 3.6336 ||:  62%|######1   | 2544/4104 [19:49<12:07,  2.14it/s]
em: 0.2151, f1: 0.2511, loss: 3.6313 ||:  63%|######2   | 2566/4104 [20:00<12:00,  2.13it/s]
em: 0.2152, f1: 0.2512, loss: 3.6274 ||:  63%|######3   | 2589/4104 [20:10<11:43,  2.15it/s]
em: 0.2155, f1: 0.2515, loss: 3.6275 ||:  64%|######3   | 2612/4104 [20:21<11:31,  2.16it/s]
em: 0.2161, f1: 0.2519, loss: 3.6262 ||:  64%|######4   | 2634/4104 [20:31<11:20,  2.16it/s]
em: 0.2163, f1: 0.2520, loss: 3.6232 ||:  65%|######4   | 2656/4104 [20:41<11:11,  2.16it/s]
em: 0.2161, f1: 0.2518, loss: 3.6237 ||:  65%|######5   | 2678/4104 [20:52<11:07,  2.14it/s]
em: 0.2160, f1: 0.2518, loss: 3.6229 ||:  66%|######5   | 2700/4104 [21:02<10:54,  2.14it/s]
em: 0.2158, f1: 0.2515, loss: 3.6235 ||:  66%|######6   | 2722/4104 [21:12<10:47,  2.13it/s]
em: 0.2162, f1: 0.2520, loss: 3.6225 ||:  67%|######6   | 2744/4104 [21:23<10:39,  2.13it/s]
em: 0.2160, f1: 0.2517, loss: 3.6215 ||:  67%|######7   | 2766/4104 [21:33<10:29,  2.13it/s]
em: 0.2157, f1: 0.2515, loss: 3.6218 ||:  68%|######7   | 2788/4104 [21:43<10:19,  2.12it/s]
em: 0.2156, f1: 0.2514, loss: 3.6225 ||:  68%|######8   | 2810/4104 [21:54<10:06,  2.13it/s]
em: 0.2159, f1: 0.2516, loss: 3.6213 ||:  69%|######9   | 2832/4104 [22:04<09:55,  2.14it/s]
em: 0.2160, f1: 0.2517, loss: 3.6218 ||:  70%|######9   | 2854/4104 [22:14<09:48,  2.13it/s]
em: 0.2161, f1: 0.2518, loss: 3.6218 ||:  70%|#######   | 2876/4104 [22:25<09:36,  2.13it/s]
em: 0.2163, f1: 0.2521, loss: 3.6239 ||:  71%|#######   | 2898/4104 [22:35<09:28,  2.12it/s]
em: 0.2163, f1: 0.2521, loss: 3.6249 ||:  71%|#######1  | 2920/4104 [22:45<09:13,  2.14it/s]
em: 0.2166, f1: 0.2524, loss: 3.6245 ||:  72%|#######1  | 2942/4104 [22:56<09:07,  2.12it/s]
em: 0.2169, f1: 0.2527, loss: 3.6234 ||:  72%|#######2  | 2964/4104 [23:06<08:58,  2.12it/s]
em: 0.2170, f1: 0.2527, loss: 3.6257 ||:  73%|#######2  | 2985/4104 [23:16<08:51,  2.10it/s]
em: 0.2169, f1: 0.2526, loss: 3.6272 ||:  73%|#######3  | 3007/4104 [23:27<08:40,  2.11it/s]
em: 0.2172, f1: 0.2528, loss: 3.6248 ||:  74%|#######3  | 3030/4104 [23:37<08:23,  2.13it/s]
em: 0.2175, f1: 0.2531, loss: 3.6231 ||:  74%|#######4  | 3053/4104 [23:48<08:16,  2.12it/s]
em: 0.2178, f1: 0.2534, loss: 3.6200 ||:  75%|#######4  | 3076/4104 [23:59<07:59,  2.14it/s]
em: 0.2180, f1: 0.2535, loss: 3.6192 ||:  76%|#######5  | 3099/4104 [24:10<07:54,  2.12it/s]
em: 0.2182, f1: 0.2537, loss: 3.6173 ||:  76%|#######6  | 3121/4104 [24:20<07:43,  2.12it/s]
em: 0.2184, f1: 0.2538, loss: 3.6176 ||:  77%|#######6  | 3143/4104 [24:30<07:31,  2.13it/s]
em: 0.2186, f1: 0.2541, loss: 3.6152 ||:  77%|#######7  | 3165/4104 [24:41<07:23,  2.12it/s]
em: 0.2191, f1: 0.2545, loss: 3.6114 ||:  78%|#######7  | 3187/4104 [24:51<07:11,  2.13it/s]
em: 0.2195, f1: 0.2549, loss: 3.6096 ||:  78%|#######8  | 3210/4104 [25:02<06:56,  2.15it/s]
em: 0.2194, f1: 0.2546, loss: 3.6086 ||:  79%|#######8  | 3232/4104 [25:12<06:44,  2.16it/s]
em: 0.2196, f1: 0.2548, loss: 3.6074 ||:  79%|#######9  | 3255/4104 [25:22<06:31,  2.17it/s]
em: 0.2199, f1: 0.2550, loss: 3.6064 ||:  80%|#######9  | 3277/4104 [25:33<06:23,  2.15it/s]
em: 0.2200, f1: 0.2550, loss: 3.6053 ||:  80%|########  | 3299/4104 [25:43<06:13,  2.16it/s]
em: 0.2201, f1: 0.2550, loss: 3.6021 ||:  81%|########  | 3322/4104 [25:53<05:59,  2.18it/s]
em: 0.2203, f1: 0.2553, loss: 3.5978 ||:  82%|########1 | 3345/4104 [26:04<05:52,  2.15it/s]
em: 0.2205, f1: 0.2554, loss: 3.5982 ||:  82%|########2 | 3367/4104 [26:14<05:40,  2.16it/s]
em: 0.2204, f1: 0.2554, loss: 3.5984 ||:  83%|########2 | 3389/4104 [26:25<05:33,  2.14it/s]
em: 0.2204, f1: 0.2554, loss: 3.5991 ||:  83%|########3 | 3412/4104 [26:35<05:19,  2.16it/s]
em: 0.2207, f1: 0.2556, loss: 3.5992 ||:  84%|########3 | 3435/4104 [26:46<05:12,  2.14it/s]
em: 0.2209, f1: 0.2559, loss: 3.5983 ||:  84%|########4 | 3456/4104 [26:56<05:06,  2.12it/s]
em: 0.2211, f1: 0.2561, loss: 3.5965 ||:  85%|########4 | 3477/4104 [27:06<04:57,  2.11it/s]
em: 0.2214, f1: 0.2565, loss: 3.5950 ||:  85%|########5 | 3499/4104 [27:16<04:43,  2.13it/s]
em: 0.2217, f1: 0.2568, loss: 3.5941 ||:  86%|########5 | 3521/4104 [27:27<04:32,  2.14it/s]
em: 0.2219, f1: 0.2569, loss: 3.5930 ||:  86%|########6 | 3543/4104 [27:37<04:22,  2.14it/s]
em: 0.2221, f1: 0.2571, loss: 3.5928 ||:  87%|########6 | 3565/4104 [27:47<04:11,  2.15it/s]
em: 0.2226, f1: 0.2577, loss: 3.5924 ||:  87%|########7 | 3587/4104 [27:57<04:01,  2.14it/s]
em: 0.2229, f1: 0.2579, loss: 3.5930 ||:  88%|########7 | 3609/4104 [28:07<03:50,  2.15it/s]
em: 0.2229, f1: 0.2579, loss: 3.5908 ||:  88%|########8 | 3631/4104 [28:18<03:42,  2.13it/s]
em: 0.2232, f1: 0.2582, loss: 3.5889 ||:  89%|########9 | 3653/4104 [28:28<03:32,  2.13it/s]
em: 0.2236, f1: 0.2586, loss: 3.5855 ||:  90%|########9 | 3675/4104 [28:39<03:21,  2.13it/s]
em: 0.2236, f1: 0.2586, loss: 3.5857 ||:  90%|######### | 3697/4104 [28:49<03:10,  2.14it/s]
em: 0.2233, f1: 0.2584, loss: 3.5864 ||:  91%|######### | 3719/4104 [28:59<02:58,  2.15it/s]
em: 0.2235, f1: 0.2587, loss: 3.5847 ||:  91%|#########1| 3741/4104 [29:09<02:50,  2.13it/s]
em: 0.2239, f1: 0.2590, loss: 3.5844 ||:  92%|#########1| 3763/4104 [29:20<02:41,  2.11it/s]
em: 0.2238, f1: 0.2589, loss: 3.5838 ||:  92%|#########2| 3785/4104 [29:30<02:30,  2.12it/s]
em: 0.2237, f1: 0.2588, loss: 3.5841 ||:  93%|#########2| 3807/4104 [29:41<02:21,  2.10it/s]
em: 0.2238, f1: 0.2589, loss: 3.5847 ||:  93%|#########3| 3829/4104 [29:51<02:09,  2.12it/s]
em: 0.2236, f1: 0.2588, loss: 3.5873 ||:  94%|#########3| 3851/4104 [30:02<02:00,  2.10it/s]
em: 0.2231, f1: 0.2584, loss: 3.5909 ||:  94%|#########4| 3873/4104 [30:12<01:49,  2.11it/s]
em: 0.2226, f1: 0.2580, loss: 3.5947 ||:  95%|#########4| 3895/4104 [30:23<01:39,  2.11it/s]
em: 0.2228, f1: 0.2582, loss: 3.5963 ||:  95%|#########5| 3918/4104 [30:33<01:26,  2.15it/s]
em: 0.2225, f1: 0.2580, loss: 3.5995 ||:  96%|#########6| 3941/4104 [30:44<01:16,  2.14it/s]
em: 0.2221, f1: 0.2576, loss: 3.6039 ||:  97%|#########6| 3963/4104 [30:54<01:06,  2.12it/s]
em: 0.2217, f1: 0.2573, loss: 3.6083 ||:  97%|#########7| 3986/4104 [31:05<00:55,  2.14it/s]
em: 0.2212, f1: 0.2569, loss: 3.6126 ||:  98%|#########7| 4009/4104 [31:16<00:44,  2.12it/s]
em: 0.2209, f1: 0.2566, loss: 3.6147 ||:  98%|#########8| 4031/4104 [31:26<00:34,  2.13it/s]
em: 0.2205, f1: 0.2562, loss: 3.6198 ||:  99%|#########8| 4054/4104 [31:37<00:23,  2.15it/s]
em: 0.2200, f1: 0.2557, loss: 3.6238 ||:  99%|#########9| 4077/4104 [31:47<00:12,  2.15it/s]
em: 0.2196, f1: 0.2554, loss: 3.6268 ||: 100%|#########9| 4099/4104 [31:58<00:02,  2.15it/s]
em: 0.2191, f1: 0.2549, loss: 3.6315 ||: : 4121it [32:08,  2.14it/s]                        
em: 0.2187, f1: 0.2546, loss: 3.6348 ||: : 4143it [32:19,  2.12it/s]
em: 0.2185, f1: 0.2544, loss: 3.6367 ||: : 4158it [32:25,  2.14it/s]

2019-05-10 08:38:43,174 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/596 [00:00<?, ?it/s]
em: 0.3547, f1: 0.3746, loss: 912164.7079 ||:   6%|6         | 37/596 [00:10<02:35,  3.60it/s]
em: 0.2974, f1: 0.3223, loss: 1601029.8407 ||:  12%|#2        | 73/596 [00:20<02:27,  3.54it/s]
em: 0.3009, f1: 0.3254, loss: 1651378.5383 ||:  18%|#8        | 109/596 [00:30<02:17,  3.55it/s]
em: 0.3010, f1: 0.3277, loss: 1663795.5807 ||:  24%|##4       | 145/596 [00:40<02:06,  3.56it/s]
em: 0.2912, f1: 0.3164, loss: 1712709.6348 ||:  30%|###       | 181/596 [00:51<01:59,  3.48it/s]
em: 0.2915, f1: 0.3169, loss: 1657112.5401 ||:  37%|###6      | 218/596 [01:01<01:47,  3.53it/s]
em: 0.2889, f1: 0.3147, loss: 1605394.6808 ||:  43%|####2     | 255/596 [01:12<01:36,  3.53it/s]
em: 0.2883, f1: 0.3141, loss: 1572167.5007 ||:  49%|####8     | 291/596 [01:23<01:27,  3.48it/s]
em: 0.2846, f1: 0.3096, loss: 1599773.2004 ||:  55%|#####4    | 327/596 [01:33<01:16,  3.51it/s]
em: 0.2824, f1: 0.3074, loss: 1580581.0772 ||:  61%|######    | 363/596 [01:44<01:07,  3.43it/s]
em: 0.2800, f1: 0.3050, loss: 1586904.3450 ||:  67%|######6   | 397/596 [01:54<00:58,  3.40it/s]
em: 0.2789, f1: 0.3031, loss: 1548035.0285 ||:  72%|#######2  | 432/596 [02:04<00:47,  3.42it/s]
em: 0.2745, f1: 0.2990, loss: 1581908.4078 ||:  78%|#######8  | 467/596 [02:14<00:37,  3.40it/s]
em: 0.2651, f1: 0.2893, loss: 1802698.6005 ||:  86%|########5 | 510/596 [02:25<00:23,  3.62it/s]
em: 0.2616, f1: 0.2852, loss: 1907778.2505 ||:  93%|#########2| 553/596 [02:35<00:11,  3.80it/s]
em: 0.2507, f1: 0.2745, loss: 1990354.8248 ||: 100%|##########| 596/596 [02:47<00:00,  3.67it/s]
em: 0.2496, f1: 0.2734, loss: 1976409.7802 ||: : 604it [02:51,  3.53it/s]                       

2019-05-10 08:41:34,491 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2019-05-10 08:41:34,491 - INFO - allennlp.training.tensorboard_writer - em              |     0.219  |     0.250
2019-05-10 08:41:34,492 - INFO - allennlp.training.tensorboard_writer - gpu_1_memory_MB |  6009.000  |       N/A
2019-05-10 08:41:34,492 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  8361.796  |       N/A
2019-05-10 08:41:34,492 - INFO - allennlp.training.tensorboard_writer - f1              |     0.254  |     0.273
2019-05-10 08:41:34,492 - INFO - allennlp.training.tensorboard_writer - loss            |     3.637  |  1976409.780
2019-05-10 08:41:34,492 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |   155.000  |       N/A
2019-05-10 08:41:39,284 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'out/baseline_bert/best.th'.
2019-05-10 08:41:43,957 - INFO - allennlp.training.trainer - Epoch duration: 00:35:26
2019-05-10 08:41:43,959 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:53:47
2019-05-10 08:41:43,959 - INFO - allennlp.training.trainer - Epoch 2/9
2019-05-10 08:41:43,959 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8362.788
2019-05-10 08:41:44,131 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 155
2019-05-10 08:41:44,131 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 6021
2019-05-10 08:41:44,139 - INFO - allennlp.training.trainer - Training
  0%|          | 0/4104 [00:00<?, ?it/s]
em: 0.2411, f1: 0.2751, loss: 3.2431 ||:   1%|          | 21/4104 [00:10<33:22,  2.04it/s]
em: 0.2500, f1: 0.2848, loss: 3.1510 ||:   1%|1         | 42/4104 [00:20<33:02,  2.05it/s]
em: 0.2461, f1: 0.2757, loss: 3.2468 ||:   2%|1         | 64/4104 [00:30<32:16,  2.09it/s]
em: 0.2566, f1: 0.2869, loss: 3.2902 ||:   2%|2         | 86/4104 [00:40<31:54,  2.10it/s]
em: 0.2529, f1: 0.2838, loss: 3.3747 ||:   3%|2         | 108/4104 [00:51<31:35,  2.11it/s]
em: 0.2524, f1: 0.2825, loss: 3.3921 ||:   3%|3         | 130/4104 [01:01<31:12,  2.12it/s]
em: 0.2458, f1: 0.2749, loss: 3.4150 ||:   4%|3         | 152/4104 [01:11<30:54,  2.13it/s]
em: 0.2471, f1: 0.2772, loss: 3.4092 ||:   4%|4         | 174/4104 [01:21<30:35,  2.14it/s]
em: 0.2487, f1: 0.2798, loss: 3.3815 ||:   5%|4         | 196/4104 [01:32<30:41,  2.12it/s]
em: 0.2494, f1: 0.2796, loss: 3.3683 ||:   5%|5         | 218/4104 [01:42<30:14,  2.14it/s]
em: 0.2474, f1: 0.2784, loss: 3.3632 ||:   6%|5         | 240/4104 [01:52<30:15,  2.13it/s]
em: 0.2517, f1: 0.2833, loss: 3.3532 ||:   6%|6         | 263/4104 [02:03<29:35,  2.16it/s]
em: 0.2516, f1: 0.2840, loss: 3.3668 ||:   7%|6         | 286/4104 [02:13<29:26,  2.16it/s]
em: 0.2496, f1: 0.2828, loss: 3.3891 ||:   8%|7         | 308/4104 [02:24<29:32,  2.14it/s]
em: 0.2500, f1: 0.2835, loss: 3.3885 ||:   8%|8         | 329/4104 [02:34<29:33,  2.13it/s]
em: 0.2511, f1: 0.2846, loss: 3.3970 ||:   9%|8         | 350/4104 [02:44<29:50,  2.10it/s]
em: 0.2490, f1: 0.2827, loss: 3.4086 ||:   9%|9         | 372/4104 [02:54<29:20,  2.12it/s]
em: 0.2486, f1: 0.2820, loss: 3.4153 ||:  10%|9         | 394/4104 [03:05<29:07,  2.12it/s]
em: 0.2463, f1: 0.2799, loss: 3.4333 ||:  10%|#         | 416/4104 [03:15<28:41,  2.14it/s]
em: 0.2461, f1: 0.2798, loss: 3.4365 ||:  11%|#         | 438/4104 [03:25<28:46,  2.12it/s]
em: 0.2460, f1: 0.2796, loss: 3.4254 ||:  11%|#1        | 460/4104 [03:35<28:31,  2.13it/s]
em: 0.2461, f1: 0.2798, loss: 3.4256 ||:  12%|#1        | 483/4104 [03:46<27:53,  2.16it/s]
em: 0.2470, f1: 0.2812, loss: 3.4136 ||:  12%|#2        | 506/4104 [03:57<27:56,  2.15it/s]
em: 0.2468, f1: 0.2808, loss: 3.3994 ||:  13%|#2        | 528/4104 [04:07<27:52,  2.14it/s]
em: 0.2462, f1: 0.2806, loss: 3.3977 ||:  13%|#3        | 550/4104 [04:17<27:49,  2.13it/s]
em: 0.2465, f1: 0.2809, loss: 3.3943 ||:  14%|#3        | 572/4104 [04:27<27:25,  2.15it/s]
em: 0.2477, f1: 0.2821, loss: 3.3913 ||:  14%|#4        | 594/4104 [04:38<27:23,  2.14it/s]
em: 0.2478, f1: 0.2827, loss: 3.3902 ||:  15%|#5        | 616/4104 [04:48<27:20,  2.13it/s]
em: 0.2485, f1: 0.2832, loss: 3.3902 ||:  16%|#5        | 638/4104 [04:58<26:57,  2.14it/s]
em: 0.2483, f1: 0.2830, loss: 3.3879 ||:  16%|#6        | 660/4104 [05:09<26:48,  2.14it/s]
em: 0.2478, f1: 0.2822, loss: 3.3780 ||:  17%|#6        | 683/4104 [05:19<26:21,  2.16it/s]
em: 0.2485, f1: 0.2832, loss: 3.3799 ||:  17%|#7        | 706/4104 [05:30<26:12,  2.16it/s]
em: 0.2492, f1: 0.2841, loss: 3.3739 ||:  18%|#7        | 728/4104 [05:40<26:15,  2.14it/s]
em: 0.2502, f1: 0.2850, loss: 3.3669 ||:  18%|#8        | 750/4104 [05:50<26:00,  2.15it/s]
em: 0.2498, f1: 0.2849, loss: 3.3657 ||:  19%|#8        | 772/4104 [06:00<25:39,  2.16it/s]
em: 0.2494, f1: 0.2844, loss: 3.3669 ||:  19%|#9        | 794/4104 [06:11<25:51,  2.13it/s]
em: 0.2500, f1: 0.2851, loss: 3.3711 ||:  20%|#9        | 816/4104 [06:21<25:38,  2.14it/s]
em: 0.2504, f1: 0.2855, loss: 3.3720 ||:  20%|##        | 838/4104 [06:31<25:18,  2.15it/s]
em: 0.2504, f1: 0.2857, loss: 3.3810 ||:  21%|##        | 861/4104 [06:42<24:58,  2.16it/s]
em: 0.2511, f1: 0.2864, loss: 3.3821 ||:  22%|##1       | 883/4104 [06:52<25:02,  2.14it/s]
em: 0.2512, f1: 0.2866, loss: 3.3858 ||:  22%|##2       | 905/4104 [07:03<25:00,  2.13it/s]
