2019-05-10 07:02:34,802 - INFO - allennlp.common.params - random_seed = 13370
2019-05-10 07:02:34,802 - INFO - allennlp.common.params - numpy_seed = 1337
2019-05-10 07:02:34,802 - INFO - allennlp.common.params - pytorch_seed = 133
2019-05-10 07:02:34,838 - INFO - allennlp.common.checks - Pytorch version: 1.0.0
2019-05-10 07:02:34,851 - INFO - allennlp.common.params - evaluate_on_test = False
2019-05-10 07:02:34,852 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'instance_format': 'drop', 'passage_length_limit': 200, 'question_length_limit': 50, 'skip_when_all_empty': ['passage_span', 'question_span', 'addition_subtraction', 'counting'], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'drop_rc_v2'} and extras set()
2019-05-10 07:02:34,852 - INFO - allennlp.common.params - dataset_reader.type = drop_rc_v2
2019-05-10 07:02:34,852 - INFO - allennlp.common.from_params - instantiating class <class 'drop_library.dataset_readers.rc_drop_reader_v2.RCDropReaderV2'> from params {'instance_format': 'drop', 'passage_length_limit': 200, 'question_length_limit': 50, 'skip_when_all_empty': ['passage_span', 'question_span', 'addition_subtraction', 'counting'], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras set()
2019-05-10 07:02:34,853 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras set()
2019-05-10 07:02:34,853 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained
2019-05-10 07:02:34,853 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'use_starting_offsets': False} and extras set()
2019-05-10 07:02:34,853 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased
2019-05-10 07:02:34,853 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False
2019-05-10 07:02:34,854 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = True
2019-05-10 07:02:34,854 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2019-05-10 07:02:34,854 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2019-05-10 07:02:35,188 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /homes/iws/patelr3/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-05-10 07:02:35,223 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'min_padding_length': 5, 'type': 'characters'} and extras set()
2019-05-10 07:02:35,223 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.type = characters
2019-05-10 07:02:35,223 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer from params {'min_padding_length': 5} and extras set()
2019-05-10 07:02:35,223 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.namespace = token_characters
2019-05-10 07:02:35,223 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.start_tokens = None
2019-05-10 07:02:35,223 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.end_tokens = None
2019-05-10 07:02:35,223 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.min_padding_length = 5
2019-05-10 07:02:35,223 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2019-05-10 07:02:35,224 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras set()
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.lazy = False
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.passage_length_limit = 200
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.question_length_limit = 50
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.skip_when_all_empty = ['passage_span', 'question_span', 'addition_subtraction', 'counting']
2019-05-10 07:02:35,224 - INFO - allennlp.common.params - dataset_reader.instance_format = drop
2019-05-10 07:02:35,225 - INFO - allennlp.common.params - dataset_reader.relaxed_span_match_for_finding_labels = True
2019-05-10 07:02:35,553 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.
2019-05-10 07:02:35,553 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'instance_format': 'drop', 'passage_length_limit': 400, 'question_length_limit': 50, 'skip_when_all_empty': [], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'drop_rc_v2'} and extras set()
2019-05-10 07:02:35,553 - INFO - allennlp.common.params - validation_dataset_reader.type = drop_rc_v2
2019-05-10 07:02:35,553 - INFO - allennlp.common.from_params - instantiating class <class 'drop_library.dataset_readers.rc_drop_reader_v2.RCDropReaderV2'> from params {'instance_format': 'drop', 'passage_length_limit': 400, 'question_length_limit': 50, 'skip_when_all_empty': [], 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False}, 'token_characters': {'min_padding_length': 5, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras set()
2019-05-10 07:02:35,553 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras set()
2019-05-10 07:02:35,553 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.type = bert-pretrained
2019-05-10 07:02:35,554 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'use_starting_offsets': False} and extras set()
2019-05-10 07:02:35,554 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased
2019-05-10 07:02:35,554 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.use_starting_offsets = False
2019-05-10 07:02:35,554 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.do_lowercase = True
2019-05-10 07:02:35,554 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.never_lowercase = None
2019-05-10 07:02:35,554 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.bert.max_pieces = 512
2019-05-10 07:02:35,858 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /homes/iws/patelr3/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-05-10 07:02:35,892 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'min_padding_length': 5, 'type': 'characters'} and extras set()
2019-05-10 07:02:35,892 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.type = characters
2019-05-10 07:02:35,892 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer from params {'min_padding_length': 5} and extras set()
2019-05-10 07:02:35,892 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.namespace = token_characters
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.start_tokens = None
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.end_tokens = None
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.min_padding_length = 5
2019-05-10 07:02:35,893 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = single_id
2019-05-10 07:02:35,893 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras set()
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tokens
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.lowercase_tokens = True
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.start_tokens = None
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.end_tokens = None
2019-05-10 07:02:35,893 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False
2019-05-10 07:02:35,894 - INFO - allennlp.common.params - validation_dataset_reader.passage_length_limit = 400
2019-05-10 07:02:35,894 - INFO - allennlp.common.params - validation_dataset_reader.question_length_limit = 50
2019-05-10 07:02:35,894 - INFO - allennlp.common.params - validation_dataset_reader.skip_when_all_empty = []
2019-05-10 07:02:35,894 - INFO - allennlp.common.params - validation_dataset_reader.instance_format = drop
2019-05-10 07:02:35,894 - INFO - allennlp.common.params - validation_dataset_reader.relaxed_span_match_for_finding_labels = True
2019-05-10 07:02:35,894 - INFO - allennlp.common.params - train_data_path = drop_dataset/drop_dataset_train.json
2019-05-10 07:02:35,894 - INFO - allennlp.training.util - Reading training data from drop_dataset/drop_dataset_train.json
0it [00:00, ?it/s]
2019-05-10 07:02:35,896 - INFO - drop_library.dataset_readers.rc_drop_reader_v2 - Reading file at drop_dataset/drop_dataset_train.json
2019-05-10 07:02:41,424 - INFO - drop_library.dataset_readers.rc_drop_reader_v2 - Reading the dataset
902it [00:10, 90.20it/s]
2991it [00:20, 108.73it/s]
5162it [00:30, 127.87it/s]
7418it [00:40, 146.95it/s]
9673it [00:50, 163.67it/s]
12017it [01:00, 179.96it/s]
14361it [01:10, 190.30it/s]
16559it [01:21, 196.03it/s]
18814it [01:31, 204.02it/s]
21069it [01:41, 209.57it/s]
23307it [01:51, 212.60it/s]
25799it [02:01, 222.36it/s]
28290it [02:13, 219.57it/s]
30682it [02:23, 225.11it/s]
33074it [02:33, 226.73it/s]
35380it [02:44, 223.32it/s]
37538it [02:56, 207.45it/s]
2019-05-10 07:05:41,839 - INFO - drop_library.dataset_readers.rc_drop_reader_v2 - Skipped 38290 questions, kept 39119 questions.
39119it [03:05, 210.35it/s]

2019-05-10 07:05:41,863 - INFO - allennlp.common.params - validation_data_path = drop_dataset/drop_dataset_dev.json
2019-05-10 07:05:41,863 - INFO - allennlp.training.util - Reading validation data from drop_dataset/drop_dataset_dev.json
0it [00:00, ?it/s]
2019-05-10 07:05:41,865 - INFO - drop_library.dataset_readers.rc_drop_reader_v2 - Reading file at drop_dataset/drop_dataset_dev.json
2019-05-10 07:05:43,198 - INFO - drop_library.dataset_readers.rc_drop_reader_v2 - Reading the dataset
3385it [00:10, 338.30it/s]
6768it [00:20, 337.36it/s]
2019-05-10 07:06:09,615 - INFO - drop_library.dataset_readers.rc_drop_reader_v2 - Skipped 0 questions, kept 9536 questions.
9536it [00:27, 343.57it/s]

2019-05-10 07:06:09,620 - INFO - allennlp.common.params - test_data_path = None
2019-05-10 07:06:09,620 - INFO - allennlp.training.trainer - From dataset instances, validation, train will be considered for vocabulary creation.
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.type = None
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.extend = False
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.directory_path = None
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = True
2019-05-10 07:06:09,620 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2019-05-10 07:06:09,620 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
0it [00:00, ?it/s]
8840it [00:10, 883.91it/s]
17680it [00:20, 879.58it/s]
26480it [00:30, 879.69it/s]
35280it [00:40, 878.16it/s]
44027it [00:50, 858.97it/s]
48655it [00:56, 858.06it/s]

2019-05-10 07:07:06,325 - INFO - allennlp.data.vocabulary - Reading pretrained tokens from: https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip
0it [00:00, ?it/s]
478164it [00:10, 47816.27it/s]
963232it [00:20, 48021.32it/s]
1451365it [00:30, 48256.13it/s]
1702926it [00:35, 48435.34it/s]

2019-05-10 07:07:42,372 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'answering_abilities': ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting'], 'dropout_prob': 0.1, 'matrix_attention_layer': {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128, 'type': 'linear'}, 'modeling_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 2, 'num_convs_per_block': 2, 'type': 'qanet_encoder'}, 'num_highway_layers': 2, 'phrase_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4, 'type': 'qanet_encoder'}, 'regularizer': [['.*', {'alpha': 1e-07, 'type': 'l2'}]], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'}}}, 'type': 'naqanet'} and extras {'vocab'}
2019-05-10 07:07:42,373 - INFO - allennlp.common.params - model.type = naqanet
2019-05-10 07:07:42,373 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.reading_comprehension.naqanet.NumericallyAugmentedQaNet'> from params {'answering_abilities': ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting'], 'dropout_prob': 0.1, 'matrix_attention_layer': {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128, 'type': 'linear'}, 'modeling_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 2, 'num_convs_per_block': 2, 'type': 'qanet_encoder'}, 'num_highway_layers': 2, 'phrase_layer': {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4, 'type': 'qanet_encoder'}, 'regularizer': [['.*', {'alpha': 1e-07, 'type': 'l2'}]], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'}}}} and extras {'vocab'}
2019-05-10 07:07:42,373 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'}}} and extras {'vocab'}
2019-05-10 07:07:42,373 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2019-05-10 07:07:42,373 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True
2019-05-10 07:07:42,373 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True, 'type': 'bert-pretrained'} and extras {'vocab'}
2019-05-10 07:07:42,374 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = bert-pretrained
2019-05-10 07:07:42,374 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': False, 'top_layer_only': True} and extras {'vocab'}
2019-05-10 07:07:42,374 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-uncased
2019-05-10 07:07:42,374 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = False
2019-05-10 07:07:42,374 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.top_layer_only = True
2019-05-10 07:07:42,695 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /homes/iws/patelr3/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2019-05-10 07:07:42,696 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /homes/iws/patelr3/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp1zfnmzbq
2019-05-10 07:07:45,969 - INFO - pytorch_pretrained_bert.modeling - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2019-05-10 07:07:54,509 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 64}, 'encoder': {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
2019-05-10 07:07:54,510 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
2019-05-10 07:07:54,510 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
2019-05-10 07:07:54,510 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
2019-05-10 07:07:54,510 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 64
2019-05-10 07:07:54,510 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
2019-05-10 07:07:54,510 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
2019-05-10 07:07:54,510 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
2019-05-10 07:07:54,511 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200, 'type': 'cnn'} and extras set()
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
2019-05-10 07:07:54,511 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'embedding_dim': 64, 'ngram_filter_sizes': [5], 'num_filters': 200} and extras set()
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 64
2019-05-10 07:07:54,511 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 200
2019-05-10 07:07:54,512 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [5]
2019-05-10 07:07:54,512 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
2019-05-10 07:07:54,514 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
2019-05-10 07:07:54,514 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'pretrained_file': 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip', 'trainable': False, 'type': 'embedding'} and extras {'vocab'}
2019-05-10 07:07:54,514 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding
2019-05-10 07:07:54,514 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None
2019-05-10 07:07:54,514 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 300
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.lower.converted.zip
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = None
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = False
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False
2019-05-10 07:07:54,515 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False
2019-05-10 07:07:54,518 - INFO - allennlp.modules.token_embedders.embedding - Reading pretrained embeddings from file
0it [00:00, ?it/s]
385849it [00:10, 38584.83it/s]
831602it [00:20, 40205.77it/s]
1300834it [00:30, 42009.98it/s]
1702926it [00:38, 44281.91it/s]

2019-05-10 07:08:33,268 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer
2019-05-10 07:08:34,343 - INFO - allennlp.modules.token_embedders.embedding - Pretrained embeddings were found for 35000 out of 35002 tokens
2019-05-10 07:08:34,352 - INFO - allennlp.common.params - model.num_highway_layers = 2
2019-05-10 07:08:34,352 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4, 'type': 'qanet_encoder'} and extras {'vocab'}
2019-05-10 07:08:34,352 - INFO - allennlp.common.params - model.phrase_layer.type = qanet_encoder
2019-05-10 07:08:34,352 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.qanet_encoder.QaNetEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 7, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 1, 'num_convs_per_block': 4} and extras {'vocab'}
2019-05-10 07:08:34,352 - INFO - allennlp.common.params - model.phrase_layer.input_dim = 128
2019-05-10 07:08:34,352 - INFO - allennlp.common.params - model.phrase_layer.hidden_dim = 128
2019-05-10 07:08:34,352 - INFO - allennlp.common.params - model.phrase_layer.attention_projection_dim = 128
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.feedforward_hidden_dim = 128
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.num_blocks = 1
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.num_convs_per_block = 4
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.conv_kernel_size = 7
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.num_attention_heads = 8
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.use_positional_encoding = True
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.dropout_prob = 0.1
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.layer_dropout_undecayed_prob = 0.1
2019-05-10 07:08:34,353 - INFO - allennlp.common.params - model.phrase_layer.attention_dropout_prob = 0
2019-05-10 07:08:34,357 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.matrix_attention.matrix_attention.MatrixAttention'> from params {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128, 'type': 'linear'} and extras {'vocab'}
2019-05-10 07:08:34,358 - INFO - allennlp.common.params - model.matrix_attention_layer.type = linear
2019-05-10 07:08:34,358 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.matrix_attention.linear_matrix_attention.LinearMatrixAttention'> from params {'combination': 'x,y,x*y', 'tensor_1_dim': 128, 'tensor_2_dim': 128} and extras {'vocab'}
2019-05-10 07:08:34,358 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_1_dim = 128
2019-05-10 07:08:34,358 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_2_dim = 128
2019-05-10 07:08:34,358 - INFO - allennlp.common.params - model.matrix_attention_layer.combination = x,y,x*y
2019-05-10 07:08:34,358 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 2, 'num_convs_per_block': 2, 'type': 'qanet_encoder'} and extras {'vocab'}
2019-05-10 07:08:34,358 - INFO - allennlp.common.params - model.modeling_layer.type = qanet_encoder
2019-05-10 07:08:34,358 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.qanet_encoder.QaNetEncoder'> from params {'attention_dropout_prob': 0, 'attention_projection_dim': 128, 'conv_kernel_size': 5, 'dropout_prob': 0.1, 'feedforward_hidden_dim': 128, 'hidden_dim': 128, 'input_dim': 128, 'layer_dropout_undecayed_prob': 0.1, 'num_attention_heads': 8, 'num_blocks': 2, 'num_convs_per_block': 2} and extras {'vocab'}
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.input_dim = 128
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.hidden_dim = 128
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.attention_projection_dim = 128
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.feedforward_hidden_dim = 128
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.num_blocks = 2
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.num_convs_per_block = 2
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.conv_kernel_size = 5
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.num_attention_heads = 8
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.use_positional_encoding = True
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.dropout_prob = 0.1
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.layer_dropout_undecayed_prob = 0.1
2019-05-10 07:08:34,359 - INFO - allennlp.common.params - model.modeling_layer.attention_dropout_prob = 0
2019-05-10 07:08:34,365 - INFO - allennlp.common.params - model.dropout_prob = 0.1
2019-05-10 07:08:34,365 - INFO - allennlp.common.params - model.regularizer = [['.*', {'alpha': 1e-07, 'type': 'l2'}]]
2019-05-10 07:08:34,365 - INFO - allennlp.common.params - model.regularizer.0.1.type = l2
2019-05-10 07:08:34,365 - INFO - allennlp.common.params - model.answering_abilities = ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting']
2019-05-10 07:08:34,373 - INFO - allennlp.nn.initializers - Initializing parameters
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.bias
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.weight
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.bias
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.weight
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.bias
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.weight
2019-05-10 07:08:34,374 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _matrix_attention._bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _matrix_attention._weight_vector
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:08:34,375 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:08:34,376 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.1.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.1.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.2.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.0.2.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.1.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.1.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.2.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_layers.1.2.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.0.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.0.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.1.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1._conv_norm_layers.1.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._combined_projection.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._combined_projection.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._output_projection.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_layer._output_projection.weight
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_norm_layer.bias
2019-05-10 07:08:34,377 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.attention_norm_layer.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.0.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.0.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.1.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward._linear_layers.1.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward_norm_layer.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_layer.encoder_block_1.feedforward_norm_layer.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.bias
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.weight
2019-05-10 07:08:34,378 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.1.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.1.weight
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.2.bias
2019-05-10 07:08:34,379 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.2.2.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.1.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.1.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.2.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_layers.3.2.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.2.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.2.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.3.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0._conv_norm_layers.3.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:08:34,380 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _phrase_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_weights_predictor.bias
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _question_weights_predictor.weight
2019-05-10 07:08:34,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2019-05-10 07:08:34,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2019-05-10 07:08:34,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2019-05-10 07:08:34,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2019-05-10 07:08:34,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2019-05-10 07:08:34,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2019-05-10 07:08:34,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2019-05-10 07:08:34,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2019-05-10 07:08:34,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2019-05-10 07:08:34,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2019-05-10 07:08:34,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2019-05-10 07:08:34,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._embedding._module.weight
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
2019-05-10 07:08:34,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.weight
2019-05-10 07:08:34,532 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 16, 'max_instances_in_memory': 600, 'sorting_keys': [['passage', 'num_tokens'], ['question', 'num_tokens']], 'type': 'bucket'} and extras set()
2019-05-10 07:08:34,532 - INFO - allennlp.common.params - iterator.type = bucket
2019-05-10 07:08:34,533 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 16, 'max_instances_in_memory': 600, 'sorting_keys': [['passage', 'num_tokens'], ['question', 'num_tokens']]} and extras set()
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.sorting_keys = [['passage', 'num_tokens'], ['question', 'num_tokens']]
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.padding_noise = 0.1
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.biggest_batch_first = False
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.batch_size = 16
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.max_instances_in_memory = 600
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.cache_instances = False
2019-05-10 07:08:34,533 - INFO - allennlp.common.params - iterator.track_epoch = False
2019-05-10 07:08:34,534 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2019-05-10 07:08:34,534 - INFO - allennlp.common.params - validation_iterator = None
2019-05-10 07:08:34,534 - INFO - allennlp.common.params - trainer.no_grad = ()
2019-05-10 07:08:34,538 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):
2019-05-10 07:08:34,538 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2019-05-10 07:08:34,538 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2019-05-10 07:08:34,538 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2019-05-10 07:08:34,539 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2019-05-10 07:08:34,540 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2019-05-10 07:08:34,541 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2019-05-10 07:08:34,542 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2019-05-10 07:08:34,543 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2019-05-10 07:08:34,544 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2019-05-10 07:08:34,545 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2019-05-10 07:08:34,546 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2019-05-10 07:08:34,547 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2019-05-10 07:08:34,548 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2019-05-10 07:08:34,549 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2019-05-10 07:08:34,550 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_tokens.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_token_characters._embedding._module.weight
2019-05-10 07:08:34,551 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _embedding_proj_layer.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _embedding_proj_layer.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _highway_layer._layers.0.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _highway_layer._layers.0.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _highway_layer._layers.1.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _highway_layer._layers.1.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _encoding_proj_layer.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _encoding_proj_layer.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.2.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.2.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.3.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_norm_layers.3.bias
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:08:34,552 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.1.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.1.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.2.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.2.2.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.1.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.1.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.2.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0._conv_layers.3.2.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:08:34,553 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _phrase_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _matrix_attention._weight_vector
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _matrix_attention._bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_proj_layer.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_proj_layer.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.0.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.0.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.1.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_norm_layers.1.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.1.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.1.bias
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.2.weight
2019-05-10 07:08:34,554 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.0.2.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.1.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.1.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.2.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0._conv_layers.1.2.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_norm_layer.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_norm_layer.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._combined_projection.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._combined_projection.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._output_projection.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.attention_layer._output_projection.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward_norm_layer.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward_norm_layer.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.0.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.0.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.1.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_0.feedforward._linear_layers.1.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.0.weight
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.0.bias
2019-05-10 07:08:34,555 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.1.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_norm_layers.1.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.1.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.1.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.2.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.0.2.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.1.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.1.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.2.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1._conv_layers.1.2.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_norm_layer.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_norm_layer.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._combined_projection.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._combined_projection.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._output_projection.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.attention_layer._output_projection.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward_norm_layer.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward_norm_layer.bias
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.0.weight
2019-05-10 07:08:34,556 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.0.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.1.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _modeling_layer.encoder_block_1.feedforward._linear_layers.1.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_weights_predictor.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_weights_predictor.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _question_weights_predictor.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _question_weights_predictor.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.0.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.0.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.1.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _answer_ability_predictor._linear_layers.1.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.0.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.0.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.1.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_start_predictor._linear_layers.1.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.0.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.0.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.1.weight
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _passage_span_end_predictor._linear_layers.1.bias
2019-05-10 07:08:34,557 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.0.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.0.bias
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.1.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _question_span_start_predictor._linear_layers.1.bias
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.0.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.0.bias
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.1.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _question_span_end_predictor._linear_layers.1.bias
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.0.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.0.bias
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.1.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _number_sign_predictor._linear_layers.1.bias
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.0.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.0.bias
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.1.weight
2019-05-10 07:08:34,558 - INFO - allennlp.training.trainer - _count_number_predictor._linear_layers.1.bias
2019-05-10 07:08:34,558 - INFO - allennlp.common.params - trainer.patience = 10
2019-05-10 07:08:34,558 - INFO - allennlp.common.params - trainer.validation_metric = +f1
2019-05-10 07:08:34,558 - INFO - allennlp.common.params - trainer.shuffle = True
2019-05-10 07:08:34,559 - INFO - allennlp.common.params - trainer.num_epochs = 10
2019-05-10 07:08:34,559 - INFO - allennlp.common.params - trainer.cuda_device = 0
2019-05-10 07:08:34,559 - INFO - allennlp.common.params - trainer.grad_norm = 5
2019-05-10 07:08:34,559 - INFO - allennlp.common.params - trainer.grad_clipping = None
2019-05-10 07:08:34,559 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2019-05-10 07:08:34,559 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2019-05-10 07:08:36,736 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2019-05-10 07:08:36,736 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2019-05-10 07:08:36,736 - INFO - allennlp.training.optimizers - Number of trainable parameters: 1055072
2019-05-10 07:08:36,736 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True
2019-05-10 07:08:36,736 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-05-10 07:08:36,736 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-05-10 07:08:36,736 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.8, 0.999]
2019-05-10 07:08:36,737 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-07
2019-05-10 07:08:36,737 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0005
2019-05-10 07:08:36,737 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.moving_average.MovingAverage'> from params {'decay': 0.9999, 'type': 'exponential'} and extras {'parameters'}
2019-05-10 07:08:36,737 - INFO - allennlp.common.params - trainer.moving_average.type = exponential
2019-05-10 07:08:36,737 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.moving_average.ExponentialMovingAverage'> from params {'decay': 0.9999} and extras {'parameters'}
2019-05-10 07:08:36,737 - INFO - allennlp.common.params - trainer.moving_average.decay = 0.9999
2019-05-10 07:08:36,737 - INFO - allennlp.common.params - trainer.moving_average.numerator = 1.0
2019-05-10 07:08:36,737 - INFO - allennlp.common.params - trainer.moving_average.denominator = 10.0
2019-05-10 07:08:36,742 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 1
2019-05-10 07:08:36,743 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2019-05-10 07:08:36,743 - INFO - allennlp.common.params - trainer.model_save_interval = None
2019-05-10 07:08:36,743 - INFO - allennlp.common.params - trainer.summary_interval = 100
2019-05-10 07:08:36,743 - INFO - allennlp.common.params - trainer.histogram_interval = None
2019-05-10 07:08:36,743 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True
2019-05-10 07:08:36,743 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False
2019-05-10 07:08:36,743 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2019-05-10 07:08:36,756 - INFO - allennlp.training.trainer - Beginning training.
2019-05-10 07:08:36,756 - INFO - allennlp.training.trainer - Epoch 0/9
2019-05-10 07:08:36,756 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 5345.732
2019-05-10 07:08:36,886 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1346
2019-05-10 07:08:36,893 - INFO - allennlp.training.trainer - Training
  0%|          | 0/2445 [00:00<?, ?it/s]
em: 0.0000, f1: 0.0287, loss: 10.0641 ||:   1%|          | 13/2445 [00:10<31:46,  1.28it/s]
em: 0.0205, f1: 0.0547, loss: 8.9052 ||:   1%|1         | 31/2445 [00:20<29:05,  1.38it/s] 
em: 0.0361, f1: 0.0731, loss: 8.3599 ||:   2%|2         | 49/2445 [00:34<29:07,  1.37it/s]
em: 0.0433, f1: 0.0847, loss: 7.9780 ||:   3%|2         | 66/2445 [00:44<27:35,  1.44it/s]
em: 0.0473, f1: 0.0896, loss: 7.8054 ||:   3%|3         | 83/2445 [00:57<28:00,  1.41it/s]
em: 0.0577, f1: 0.1029, loss: 7.5112 ||:   4%|4         | 100/2445 [01:07<26:39,  1.47it/s]
em: 0.0698, f1: 0.1176, loss: 7.2813 ||:   5%|4         | 117/2445 [01:20<27:15,  1.42it/s]
em: 0.0754, f1: 0.1253, loss: 7.0854 ||:   5%|5         | 133/2445 [01:30<26:12,  1.47it/s]
em: 0.0807, f1: 0.1322, loss: 6.9355 ||:   6%|6         | 150/2445 [01:40<25:15,  1.51it/s]
em: 0.0886, f1: 0.1401, loss: 6.8439 ||:   7%|6         | 167/2445 [01:56<27:40,  1.37it/s]
em: 0.1009, f1: 0.1546, loss: 6.6979 ||:   8%|7         | 184/2445 [02:06<26:07,  1.44it/s]
em: 0.1033, f1: 0.1607, loss: 6.6186 ||:   8%|8         | 201/2445 [02:19<26:38,  1.40it/s]
em: 0.1041, f1: 0.1610, loss: 6.5782 ||:   9%|8         | 218/2445 [02:29<25:27,  1.46it/s]
em: 0.1075, f1: 0.1634, loss: 6.5189 ||:  10%|9         | 235/2445 [02:42<25:55,  1.42it/s]
em: 0.1109, f1: 0.1686, loss: 6.4479 ||:  10%|#         | 251/2445 [02:52<25:03,  1.46it/s]
em: 0.1143, f1: 0.1723, loss: 6.3899 ||:  11%|#         | 267/2445 [03:04<25:23,  1.43it/s]
em: 0.1156, f1: 0.1740, loss: 6.3369 ||:  12%|#1        | 283/2445 [03:14<24:29,  1.47it/s]
em: 0.1174, f1: 0.1760, loss: 6.2928 ||:  12%|#2        | 300/2445 [03:24<23:30,  1.52it/s]
em: 0.1218, f1: 0.1807, loss: 6.2218 ||:  13%|#2        | 317/2445 [03:37<24:09,  1.47it/s]
em: 0.1248, f1: 0.1834, loss: 6.1763 ||:  14%|#3        | 333/2445 [03:47<23:28,  1.50it/s]
em: 0.1270, f1: 0.1861, loss: 6.1396 ||:  14%|#4        | 349/2445 [03:59<24:07,  1.45it/s]
em: 0.1278, f1: 0.1864, loss: 6.1076 ||:  15%|#4        | 365/2445 [04:09<23:24,  1.48it/s]
em: 0.1313, f1: 0.1895, loss: 6.0688 ||:  16%|#5        | 381/2445 [04:21<24:05,  1.43it/s]
em: 0.1330, f1: 0.1915, loss: 6.0298 ||:  16%|#6        | 398/2445 [04:32<22:57,  1.49it/s]
em: 0.1334, f1: 0.1915, loss: 5.9984 ||:  17%|#6        | 415/2445 [04:42<22:16,  1.52it/s]
em: 0.1348, f1: 0.1936, loss: 5.9829 ||:  18%|#7        | 432/2445 [04:55<22:54,  1.46it/s]
em: 0.1378, f1: 0.1973, loss: 5.9375 ||:  18%|#8        | 449/2445 [05:05<22:02,  1.51it/s]
em: 0.1401, f1: 0.2003, loss: 5.9033 ||:  19%|#9        | 466/2445 [05:18<22:23,  1.47it/s]
em: 0.1405, f1: 0.2005, loss: 5.8985 ||:  20%|#9        | 483/2445 [05:28<21:30,  1.52it/s]
em: 0.1411, f1: 0.2014, loss: 5.8722 ||:  20%|##        | 500/2445 [05:41<22:19,  1.45it/s]
em: 0.1430, f1: 0.2030, loss: 5.8488 ||:  21%|##1       | 518/2445 [05:51<21:07,  1.52it/s]
em: 0.1453, f1: 0.2064, loss: 5.8165 ||:  22%|##1       | 536/2445 [06:05<21:41,  1.47it/s]
em: 0.1468, f1: 0.2077, loss: 5.7926 ||:  23%|##2       | 553/2445 [06:15<20:51,  1.51it/s]
em: 0.1476, f1: 0.2094, loss: 5.7756 ||:  23%|##3       | 570/2445 [06:26<20:27,  1.53it/s]
em: 0.1493, f1: 0.2111, loss: 5.7572 ||:  24%|##3       | 586/2445 [06:38<21:02,  1.47it/s]
em: 0.1506, f1: 0.2127, loss: 5.7273 ||:  25%|##4       | 602/2445 [06:48<20:29,  1.50it/s]
em: 0.1523, f1: 0.2142, loss: 5.7171 ||:  25%|##5       | 618/2445 [07:00<21:13,  1.43it/s]
em: 0.1523, f1: 0.2144, loss: 5.7107 ||:  26%|##5       | 635/2445 [07:10<20:07,  1.50it/s]
em: 0.1526, f1: 0.2145, loss: 5.6980 ||:  27%|##6       | 652/2445 [07:23<20:40,  1.45it/s]
em: 0.1541, f1: 0.2160, loss: 5.6836 ||:  27%|##7       | 668/2445 [07:33<19:57,  1.48it/s]
em: 0.1552, f1: 0.2172, loss: 5.6699 ||:  28%|##7       | 684/2445 [07:43<19:25,  1.51it/s]
em: 0.1554, f1: 0.2176, loss: 5.6521 ||:  29%|##8       | 700/2445 [07:58<21:26,  1.36it/s]
em: 0.1577, f1: 0.2199, loss: 5.6259 ||:  29%|##9       | 717/2445 [08:08<20:06,  1.43it/s]
em: 0.1582, f1: 0.2203, loss: 5.6153 ||:  30%|###       | 734/2445 [08:21<20:19,  1.40it/s]
em: 0.1596, f1: 0.2215, loss: 5.5950 ||:  31%|###       | 750/2445 [08:31<19:31,  1.45it/s]
em: 0.1608, f1: 0.2221, loss: 5.5856 ||:  31%|###1      | 766/2445 [08:43<19:49,  1.41it/s]
em: 0.1607, f1: 0.2220, loss: 5.5728 ||:  32%|###2      | 783/2445 [08:54<18:49,  1.47it/s]
em: 0.1615, f1: 0.2227, loss: 5.5616 ||:  33%|###2      | 800/2445 [09:06<19:08,  1.43it/s]
em: 0.1624, f1: 0.2236, loss: 5.5452 ||:  33%|###3      | 817/2445 [09:17<18:21,  1.48it/s]
em: 0.1631, f1: 0.2242, loss: 5.5328 ||:  34%|###4      | 833/2445 [09:27<17:58,  1.49it/s]
em: 0.1641, f1: 0.2254, loss: 5.5137 ||:  35%|###4      | 849/2445 [09:40<18:41,  1.42it/s]
em: 0.1654, f1: 0.2269, loss: 5.4950 ||:  35%|###5      | 865/2445 [09:50<17:56,  1.47it/s]
em: 0.1671, f1: 0.2283, loss: 5.4862 ||:  36%|###6      | 881/2445 [10:02<18:23,  1.42it/s]
em: 0.1675, f1: 0.2290, loss: 5.4753 ||:  37%|###6      | 897/2445 [10:13<17:48,  1.45it/s]
em: 0.1675, f1: 0.2288, loss: 5.4634 ||:  37%|###7      | 913/2445 [10:25<18:06,  1.41it/s]
em: 0.1686, f1: 0.2297, loss: 5.4534 ||:  38%|###7      | 929/2445 [10:35<17:23,  1.45it/s]
em: 0.1687, f1: 0.2299, loss: 5.4400 ||:  39%|###8      | 945/2445 [10:45<16:50,  1.48it/s]
em: 0.1694, f1: 0.2308, loss: 5.4310 ||:  39%|###9      | 961/2445 [10:57<17:06,  1.45it/s]
em: 0.1697, f1: 0.2310, loss: 5.4236 ||:  40%|####      | 978/2445 [11:07<16:16,  1.50it/s]
em: 0.1701, f1: 0.2314, loss: 5.4131 ||:  41%|####      | 995/2445 [11:20<16:47,  1.44it/s]
em: 0.1706, f1: 0.2316, loss: 5.3992 ||:  41%|####1     | 1011/2445 [11:31<16:14,  1.47it/s]
em: 0.1707, f1: 0.2319, loss: 5.3912 ||:  42%|####2     | 1027/2445 [11:42<16:24,  1.44it/s]
em: 0.1715, f1: 0.2327, loss: 5.3805 ||:  43%|####2     | 1043/2445 [11:52<15:49,  1.48it/s]
em: 0.1719, f1: 0.2332, loss: 5.3680 ||:  43%|####3     | 1060/2445 [12:03<15:15,  1.51it/s]
em: 0.1728, f1: 0.2342, loss: 5.3563 ||:  44%|####4     | 1077/2445 [12:16<15:37,  1.46it/s]
em: 0.1739, f1: 0.2354, loss: 5.3483 ||:  45%|####4     | 1093/2445 [12:26<15:02,  1.50it/s]
em: 0.1738, f1: 0.2356, loss: 5.3432 ||:  45%|####5     | 1109/2445 [12:38<15:28,  1.44it/s]
em: 0.1738, f1: 0.2356, loss: 5.3347 ||:  46%|####6     | 1126/2445 [12:48<14:49,  1.48it/s]
em: 0.1737, f1: 0.2356, loss: 5.3307 ||:  47%|####6     | 1142/2445 [13:00<14:58,  1.45it/s]
em: 0.1739, f1: 0.2359, loss: 5.3224 ||:  47%|####7     | 1158/2445 [13:10<14:24,  1.49it/s]
em: 0.1746, f1: 0.2365, loss: 5.3101 ||:  48%|####8     | 1174/2445 [13:20<14:06,  1.50it/s]
em: 0.1750, f1: 0.2370, loss: 5.2984 ||:  49%|####8     | 1190/2445 [13:33<14:27,  1.45it/s]
em: 0.1763, f1: 0.2382, loss: 5.2891 ||:  49%|####9     | 1206/2445 [13:43<14:06,  1.46it/s]
em: 0.1766, f1: 0.2387, loss: 5.2857 ||:  50%|####9     | 1222/2445 [13:55<14:21,  1.42it/s]
em: 0.1775, f1: 0.2396, loss: 5.2809 ||:  51%|#####     | 1239/2445 [14:06<13:39,  1.47it/s]
em: 0.1779, f1: 0.2400, loss: 5.2745 ||:  51%|#####1    | 1256/2445 [14:18<13:47,  1.44it/s]
em: 0.1788, f1: 0.2409, loss: 5.2633 ||:  52%|#####2    | 1272/2445 [14:29<13:18,  1.47it/s]
em: 0.1791, f1: 0.2413, loss: 5.2561 ||:  53%|#####2    | 1289/2445 [14:39<12:46,  1.51it/s]
em: 0.1798, f1: 0.2424, loss: 5.2434 ||:  53%|#####3    | 1306/2445 [14:52<12:58,  1.46it/s]
em: 0.1807, f1: 0.2433, loss: 5.2314 ||:  54%|#####4    | 1323/2445 [15:02<12:23,  1.51it/s]
em: 0.1816, f1: 0.2444, loss: 5.2207 ||:  55%|#####4    | 1340/2445 [15:17<13:25,  1.37it/s]
em: 0.1830, f1: 0.2458, loss: 5.2078 ||:  56%|#####5    | 1357/2445 [15:27<12:32,  1.45it/s]
em: 0.1839, f1: 0.2465, loss: 5.2004 ||:  56%|#####6    | 1374/2445 [15:40<12:32,  1.42it/s]
em: 0.1841, f1: 0.2466, loss: 5.1968 ||:  57%|#####6    | 1390/2445 [15:50<11:57,  1.47it/s]
em: 0.1846, f1: 0.2470, loss: 5.1876 ||:  58%|#####7    | 1407/2445 [16:02<12:02,  1.44it/s]
em: 0.1849, f1: 0.2473, loss: 5.1836 ||:  58%|#####8    | 1423/2445 [16:13<11:38,  1.46it/s]
em: 0.1855, f1: 0.2478, loss: 5.1753 ||:  59%|#####8    | 1439/2445 [16:23<11:14,  1.49it/s]
em: 0.1855, f1: 0.2482, loss: 5.1702 ||:  60%|#####9    | 1455/2445 [16:35<11:22,  1.45it/s]
em: 0.1862, f1: 0.2489, loss: 5.1636 ||:  60%|######    | 1472/2445 [16:45<10:52,  1.49it/s]
em: 0.1869, f1: 0.2496, loss: 5.1571 ||:  61%|######    | 1488/2445 [16:57<10:52,  1.47it/s]
em: 0.1875, f1: 0.2501, loss: 5.1489 ||:  62%|######1   | 1504/2445 [17:07<10:28,  1.50it/s]
em: 0.1883, f1: 0.2507, loss: 5.1378 ||:  62%|######2   | 1521/2445 [17:19<10:30,  1.46it/s]
em: 0.1887, f1: 0.2509, loss: 5.1328 ||:  63%|######2   | 1537/2445 [17:29<10:09,  1.49it/s]
em: 0.1894, f1: 0.2518, loss: 5.1251 ||:  64%|######3   | 1554/2445 [17:40<09:45,  1.52it/s]
em: 0.1899, f1: 0.2521, loss: 5.1176 ||:  64%|######4   | 1571/2445 [17:52<09:50,  1.48it/s]
em: 0.1905, f1: 0.2529, loss: 5.1097 ||:  65%|######4   | 1588/2445 [18:03<09:24,  1.52it/s]
em: 0.1911, f1: 0.2531, loss: 5.1022 ||:  66%|######5   | 1605/2445 [18:16<09:41,  1.44it/s]
em: 0.1912, f1: 0.2533, loss: 5.0977 ||:  66%|######6   | 1622/2445 [18:26<09:08,  1.50it/s]
em: 0.1915, f1: 0.2536, loss: 5.0933 ||:  67%|######7   | 1639/2445 [18:39<09:20,  1.44it/s]
em: 0.1916, f1: 0.2536, loss: 5.0893 ||:  68%|######7   | 1655/2445 [18:50<08:59,  1.46it/s]
em: 0.1919, f1: 0.2542, loss: 5.0855 ||:  68%|######8   | 1671/2445 [19:00<08:39,  1.49it/s]
em: 0.1932, f1: 0.2556, loss: 5.0760 ||:  69%|######8   | 1687/2445 [19:11<08:40,  1.46it/s]
em: 0.1938, f1: 0.2565, loss: 5.0697 ||:  70%|######9   | 1703/2445 [19:22<08:23,  1.47it/s]
em: 0.1946, f1: 0.2575, loss: 5.0630 ||:  70%|#######   | 1719/2445 [19:34<08:22,  1.44it/s]
em: 0.1951, f1: 0.2579, loss: 5.0614 ||:  71%|#######   | 1735/2445 [19:44<08:04,  1.46it/s]
em: 0.1954, f1: 0.2582, loss: 5.0616 ||:  72%|#######1  | 1751/2445 [19:56<08:05,  1.43it/s]
em: 0.1959, f1: 0.2585, loss: 5.0599 ||:  72%|#######2  | 1768/2445 [20:06<07:37,  1.48it/s]
em: 0.1964, f1: 0.2589, loss: 5.0574 ||:  73%|#######3  | 1785/2445 [20:17<07:20,  1.50it/s]
em: 0.1969, f1: 0.2594, loss: 5.0502 ||:  74%|#######3  | 1801/2445 [20:29<07:21,  1.46it/s]
em: 0.1969, f1: 0.2593, loss: 5.0474 ||:  74%|#######4  | 1817/2445 [20:39<07:01,  1.49it/s]
em: 0.1974, f1: 0.2599, loss: 5.0417 ||:  75%|#######4  | 1833/2445 [20:52<07:07,  1.43it/s]
em: 0.1984, f1: 0.2608, loss: 5.0319 ||:  76%|#######5  | 1850/2445 [21:02<06:41,  1.48it/s]
em: 0.1991, f1: 0.2614, loss: 5.0258 ||:  76%|#######6  | 1867/2445 [21:15<06:45,  1.42it/s]
em: 0.1996, f1: 0.2618, loss: 5.0203 ||:  77%|#######7  | 1884/2445 [21:26<06:20,  1.47it/s]
em: 0.2001, f1: 0.2622, loss: 5.0130 ||:  78%|#######7  | 1901/2445 [21:38<06:20,  1.43it/s]
em: 0.2006, f1: 0.2626, loss: 5.0063 ||:  78%|#######8  | 1918/2445 [21:49<05:55,  1.48it/s]
em: 0.2011, f1: 0.2631, loss: 4.9985 ||:  79%|#######9  | 1935/2445 [21:59<05:34,  1.53it/s]
em: 0.2015, f1: 0.2635, loss: 4.9955 ||:  80%|#######9  | 1952/2445 [22:12<05:35,  1.47it/s]
em: 0.2021, f1: 0.2640, loss: 4.9908 ||:  81%|########  | 1969/2445 [22:22<05:12,  1.52it/s]
em: 0.2026, f1: 0.2644, loss: 4.9859 ||:  81%|########1 | 1986/2445 [22:34<05:11,  1.47it/s]
em: 0.2030, f1: 0.2648, loss: 4.9792 ||:  82%|########1 | 2003/2445 [22:45<04:52,  1.51it/s]
em: 0.2036, f1: 0.2654, loss: 4.9755 ||:  83%|########2 | 2019/2445 [22:57<04:54,  1.44it/s]
em: 0.2040, f1: 0.2658, loss: 4.9718 ||:  83%|########3 | 2035/2445 [23:08<04:37,  1.48it/s]
em: 0.2042, f1: 0.2661, loss: 4.9689 ||:  84%|########3 | 2051/2445 [23:18<04:22,  1.50it/s]
em: 0.2049, f1: 0.2669, loss: 4.9638 ||:  85%|########4 | 2067/2445 [23:30<04:22,  1.44it/s]
em: 0.2055, f1: 0.2676, loss: 4.9592 ||:  85%|########5 | 2083/2445 [23:40<04:04,  1.48it/s]
em: 0.2063, f1: 0.2683, loss: 4.9542 ||:  86%|########5 | 2099/2445 [23:52<03:58,  1.45it/s]
em: 0.2067, f1: 0.2687, loss: 4.9509 ||:  87%|########6 | 2115/2445 [24:02<03:44,  1.47it/s]
em: 0.2074, f1: 0.2693, loss: 4.9463 ||:  87%|########7 | 2131/2445 [24:17<03:57,  1.32it/s]
em: 0.2080, f1: 0.2699, loss: 4.9441 ||:  88%|########7 | 2147/2445 [24:27<03:35,  1.38it/s]
em: 0.2083, f1: 0.2703, loss: 4.9413 ||:  89%|########8 | 2164/2445 [24:38<03:13,  1.45it/s]
em: 0.2084, f1: 0.2704, loss: 4.9379 ||:  89%|########9 | 2181/2445 [24:50<03:06,  1.42it/s]
em: 0.2082, f1: 0.2702, loss: 4.9307 ||:  90%|########9 | 2197/2445 [25:01<02:50,  1.46it/s]
em: 0.2085, f1: 0.2705, loss: 4.9285 ||:  91%|######### | 2213/2445 [25:12<02:43,  1.42it/s]
em: 0.2087, f1: 0.2706, loss: 4.9240 ||:  91%|#########1| 2229/2445 [25:23<02:27,  1.46it/s]
em: 0.2090, f1: 0.2709, loss: 4.9198 ||:  92%|#########1| 2245/2445 [25:35<02:21,  1.42it/s]
em: 0.2090, f1: 0.2708, loss: 4.9170 ||:  92%|#########2| 2261/2445 [25:45<02:07,  1.45it/s]
em: 0.2094, f1: 0.2712, loss: 4.9147 ||:  93%|#########3| 2277/2445 [25:55<01:52,  1.49it/s]
em: 0.2098, f1: 0.2718, loss: 4.9092 ||:  94%|#########3| 2293/2445 [26:07<01:45,  1.44it/s]
em: 0.2100, f1: 0.2722, loss: 4.9044 ||:  94%|#########4| 2309/2445 [26:18<01:33,  1.46it/s]
em: 0.2102, f1: 0.2726, loss: 4.8995 ||:  95%|#########5| 2325/2445 [26:30<01:25,  1.41it/s]
em: 0.2105, f1: 0.2731, loss: 4.8941 ||:  96%|#########5| 2342/2445 [26:41<01:10,  1.47it/s]
em: 0.2109, f1: 0.2735, loss: 4.8874 ||:  96%|#########6| 2359/2445 [26:53<00:59,  1.43it/s]
em: 0.2108, f1: 0.2734, loss: 4.8849 ||:  97%|#########7| 2376/2445 [27:04<00:46,  1.49it/s]
em: 0.2110, f1: 0.2739, loss: 4.8776 ||:  98%|#########7| 2393/2445 [27:15<00:34,  1.50it/s]
em: 0.2110, f1: 0.2741, loss: 4.8748 ||:  99%|#########8| 2409/2445 [27:26<00:24,  1.47it/s]
em: 0.2111, f1: 0.2744, loss: 4.8697 ||:  99%|#########9| 2425/2445 [27:36<00:13,  1.50it/s]
em: 0.2106, f1: 0.2742, loss: 4.8650 ||: 100%|#########9| 2441/2445 [27:48<00:02,  1.45it/s]
em: 0.2106, f1: 0.2744, loss: 4.8612 ||: : 2457it [27:59,  1.48it/s]                        
em: 0.2105, f1: 0.2744, loss: 4.8576 ||: : 2473it [28:09,  1.50it/s]
em: 0.2105, f1: 0.2743, loss: 4.8564 ||: : 2478it [28:12,  1.46it/s]

2019-05-10 07:36:49,339 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/596 [00:00<?, ?it/s]
em: 0.2446, f1: 0.2662, loss: 4293479.6413 ||:   4%|3         | 23/596 [00:10<04:11,  2.28it/s]
em: 0.2610, f1: 0.2842, loss: 4402175.3750 ||:   8%|7         | 46/596 [00:25<04:39,  1.96it/s]
em: 0.2510, f1: 0.2791, loss: 4412880.4015 ||:  11%|#1        | 66/596 [00:35<04:29,  1.96it/s]
em: 0.2404, f1: 0.2715, loss: 4447676.0305 ||:  14%|#4        | 86/596 [00:48<04:40,  1.82it/s]
em: 0.2423, f1: 0.2721, loss: 4569576.9976 ||:  18%|#7        | 106/596 [00:58<04:23,  1.86it/s]
em: 0.2349, f1: 0.2661, loss: 4593255.5010 ||:  21%|##1       | 126/596 [01:10<04:19,  1.81it/s]
em: 0.2274, f1: 0.2588, loss: 4711208.3905 ||:  24%|##4       | 145/596 [01:20<04:06,  1.83it/s]
em: 0.2215, f1: 0.2507, loss: 4786586.8285 ||:  28%|##7       | 164/596 [01:33<04:09,  1.73it/s]
em: 0.2137, f1: 0.2426, loss: 4781422.2623 ||:  31%|###       | 183/596 [01:43<03:54,  1.76it/s]
em: 0.2074, f1: 0.2352, loss: 4866956.9220 ||:  34%|###3      | 202/596 [01:54<03:44,  1.75it/s]
em: 0.2039, f1: 0.2329, loss: 4828267.2680 ||:  37%|###7      | 222/596 [02:04<03:26,  1.81it/s]
em: 0.2050, f1: 0.2333, loss: 4837294.8936 ||:  41%|####      | 242/596 [02:15<03:15,  1.81it/s]
em: 0.2059, f1: 0.2359, loss: 4825193.1121 ||:  44%|####3     | 261/596 [02:26<03:09,  1.77it/s]
em: 0.2067, f1: 0.2363, loss: 4820790.0703 ||:  47%|####6     | 279/596 [02:37<03:00,  1.76it/s]
em: 0.2042, f1: 0.2339, loss: 4838508.2479 ||:  50%|#####     | 298/596 [02:47<02:48,  1.77it/s]
em: 0.2031, f1: 0.2319, loss: 4852130.8668 ||:  53%|#####3    | 317/596 [02:57<02:34,  1.80it/s]
em: 0.2029, f1: 0.2314, loss: 4841891.4075 ||:  56%|#####6    | 336/596 [03:09<02:29,  1.74it/s]
em: 0.2021, f1: 0.2301, loss: 4890228.1152 ||:  59%|#####9    | 353/596 [03:20<02:21,  1.71it/s]
em: 0.2060, f1: 0.2341, loss: 4823590.2141 ||:  62%|######2   | 372/596 [03:30<02:07,  1.75it/s]
em: 0.2050, f1: 0.2328, loss: 4819374.9419 ||:  66%|######5   | 391/596 [03:42<02:00,  1.71it/s]
em: 0.2035, f1: 0.2307, loss: 4835767.9593 ||:  69%|######8   | 411/596 [03:52<01:44,  1.78it/s]
em: 0.2028, f1: 0.2307, loss: 4830337.9743 ||:  72%|#######2  | 431/596 [04:04<01:35,  1.74it/s]
em: 0.2004, f1: 0.2294, loss: 4832963.6930 ||:  75%|#######5  | 449/596 [04:14<01:23,  1.75it/s]
em: 0.1978, f1: 0.2271, loss: 4875536.8494 ||:  78%|#######8  | 467/596 [04:24<01:13,  1.74it/s]
em: 0.1937, f1: 0.2228, loss: 4961657.8930 ||:  82%|########2 | 489/596 [04:34<00:57,  1.86it/s]
em: 0.1930, f1: 0.2220, loss: 4964738.7844 ||:  86%|########6 | 514/596 [04:45<00:40,  2.01it/s]
em: 0.1936, f1: 0.2222, loss: 4953619.2308 ||:  90%|######### | 539/596 [04:57<00:28,  2.00it/s]
em: 0.1886, f1: 0.2174, loss: 5022203.8604 ||:  94%|#########4| 563/596 [05:07<00:15,  2.11it/s]
em: 0.1844, f1: 0.2135, loss: 5080921.2852 ||:  98%|#########8| 587/596 [05:25<00:04,  1.82it/s]
em: 0.1826, f1: 0.2117, loss: 5097592.7108 ||: : 602it [05:35,  1.68it/s]                       
em: 0.1823, f1: 0.2114, loss: 5103478.1671 ||: : 604it [05:37,  1.79it/s]

2019-05-10 07:42:26,412 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2019-05-10 07:42:26,413 - INFO - allennlp.training.tensorboard_writer - loss            |     4.856  |  5103478.167
2019-05-10 07:42:26,413 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1346.000  |       N/A
2019-05-10 07:42:26,414 - INFO - allennlp.training.tensorboard_writer - em              |     0.210  |     0.182
2019-05-10 07:42:26,414 - INFO - allennlp.training.tensorboard_writer - f1              |     0.274  |     0.211
2019-05-10 07:42:26,415 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  5345.732  |       N/A
2019-05-10 07:43:08,770 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'out/rc_bert_simple_v2/best.th'.
2019-05-10 07:43:50,344 - INFO - allennlp.training.trainer - Epoch duration: 00:35:13
2019-05-10 07:43:50,344 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:17:02
2019-05-10 07:43:50,345 - INFO - allennlp.training.trainer - Epoch 1/9
2019-05-10 07:43:50,345 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6474.356
2019-05-10 07:43:50,479 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4561
2019-05-10 07:43:50,487 - INFO - allennlp.training.trainer - Training
  0%|          | 0/2445 [00:00<?, ?it/s]
em: 0.3320, f1: 0.3895, loss: 3.8085 ||:   1%|          | 16/2445 [00:10<26:35,  1.52it/s]
em: 0.3308, f1: 0.3960, loss: 3.6673 ||:   1%|1         | 33/2445 [00:20<25:37,  1.57it/s]
em: 0.3220, f1: 0.3782, loss: 3.8669 ||:   2%|2         | 50/2445 [00:31<25:37,  1.56it/s]
em: 0.3173, f1: 0.3687, loss: 4.0212 ||:   3%|2         | 66/2445 [00:42<25:35,  1.55it/s]
em: 0.3129, f1: 0.3651, loss: 4.0540 ||:   3%|3         | 83/2445 [00:52<25:09,  1.56it/s]
em: 0.3090, f1: 0.3655, loss: 4.0563 ||:   4%|4         | 100/2445 [01:03<24:55,  1.57it/s]
em: 0.3073, f1: 0.3644, loss: 4.0240 ||:   5%|4         | 116/2445 [01:14<24:59,  1.55it/s]
em: 0.2998, f1: 0.3582, loss: 4.0220 ||:   5%|5         | 132/2445 [01:24<24:37,  1.57it/s]
em: 0.2948, f1: 0.3509, loss: 4.0178 ||:   6%|6         | 148/2445 [01:34<24:30,  1.56it/s]
em: 0.2975, f1: 0.3529, loss: 4.0449 ||:   7%|6         | 164/2445 [01:45<24:39,  1.54it/s]
em: 0.3022, f1: 0.3598, loss: 4.0190 ||:   7%|7         | 182/2445 [01:55<23:47,  1.59it/s]
em: 0.3047, f1: 0.3641, loss: 4.0241 ||:   8%|8         | 199/2445 [02:06<23:51,  1.57it/s]
em: 0.3048, f1: 0.3643, loss: 4.0423 ||:   9%|8         | 215/2445 [02:17<23:44,  1.56it/s]
em: 0.3004, f1: 0.3596, loss: 4.0944 ||:   9%|9         | 231/2445 [02:27<24:00,  1.54it/s]
em: 0.3018, f1: 0.3604, loss: 4.0726 ||:  10%|#         | 248/2445 [02:38<23:36,  1.55it/s]
em: 0.3013, f1: 0.3598, loss: 4.0669 ||:  11%|#         | 264/2445 [02:48<23:19,  1.56it/s]
em: 0.3009, f1: 0.3585, loss: 4.0678 ||:  11%|#1        | 280/2445 [02:59<23:30,  1.54it/s]
em: 0.3053, f1: 0.3636, loss: 4.0585 ||:  12%|#2        | 298/2445 [03:10<22:38,  1.58it/s]
em: 0.3054, f1: 0.3625, loss: 4.0339 ||:  13%|#2        | 315/2445 [03:21<22:32,  1.57it/s]
em: 0.3032, f1: 0.3597, loss: 4.0344 ||:  14%|#3        | 331/2445 [03:31<22:33,  1.56it/s]
em: 0.3006, f1: 0.3570, loss: 4.0435 ||:  14%|#4        | 347/2445 [03:41<22:29,  1.55it/s]
em: 0.2992, f1: 0.3560, loss: 4.0564 ||:  15%|#4        | 363/2445 [03:52<22:29,  1.54it/s]
em: 0.2980, f1: 0.3545, loss: 4.0542 ||:  16%|#5        | 379/2445 [04:02<22:06,  1.56it/s]
em: 0.2984, f1: 0.3550, loss: 4.0470 ||:  16%|#6        | 395/2445 [04:12<21:49,  1.57it/s]
em: 0.2971, f1: 0.3536, loss: 4.0552 ||:  17%|#6        | 412/2445 [04:23<21:22,  1.59it/s]
em: 0.2950, f1: 0.3520, loss: 4.0614 ||:  18%|#7        | 429/2445 [04:34<21:25,  1.57it/s]
em: 0.2956, f1: 0.3527, loss: 4.0553 ||:  18%|#8        | 446/2445 [04:44<21:05,  1.58it/s]
em: 0.2957, f1: 0.3527, loss: 4.0564 ||:  19%|#8        | 463/2445 [04:55<20:54,  1.58it/s]
em: 0.2942, f1: 0.3513, loss: 4.0677 ||:  20%|#9        | 480/2445 [05:05<20:36,  1.59it/s]
em: 0.2927, f1: 0.3501, loss: 4.0810 ||:  20%|##        | 497/2445 [05:16<20:22,  1.59it/s]
em: 0.2914, f1: 0.3488, loss: 4.0863 ||:  21%|##1       | 514/2445 [05:26<20:01,  1.61it/s]
em: 0.2904, f1: 0.3484, loss: 4.0926 ||:  22%|##1       | 531/2445 [05:37<19:54,  1.60it/s]
em: 0.2911, f1: 0.3493, loss: 4.0936 ||:  22%|##2       | 547/2445 [05:47<19:49,  1.60it/s]
em: 0.2920, f1: 0.3502, loss: 4.0962 ||:  23%|##3       | 563/2445 [05:57<19:43,  1.59it/s]
em: 0.2925, f1: 0.3513, loss: 4.1006 ||:  24%|##3       | 579/2445 [06:08<19:48,  1.57it/s]
em: 0.2936, f1: 0.3522, loss: 4.0992 ||:  24%|##4       | 596/2445 [06:18<19:17,  1.60it/s]
em: 0.2937, f1: 0.3521, loss: 4.1034 ||:  25%|##5       | 613/2445 [06:30<19:33,  1.56it/s]
em: 0.2924, f1: 0.3505, loss: 4.1164 ||:  26%|##5       | 630/2445 [06:40<19:00,  1.59it/s]
em: 0.2927, f1: 0.3503, loss: 4.1232 ||:  26%|##6       | 647/2445 [06:51<18:54,  1.58it/s]
em: 0.2927, f1: 0.3502, loss: 4.1271 ||:  27%|##7       | 663/2445 [07:01<18:55,  1.57it/s]
em: 0.2923, f1: 0.3501, loss: 4.1296 ||:  28%|##7       | 680/2445 [07:12<18:36,  1.58it/s]
em: 0.2919, f1: 0.3497, loss: 4.1290 ||:  29%|##8       | 697/2445 [07:23<18:45,  1.55it/s]
em: 0.2914, f1: 0.3492, loss: 4.1254 ||:  29%|##9       | 713/2445 [07:33<18:29,  1.56it/s]
em: 0.2904, f1: 0.3478, loss: 4.1275 ||:  30%|##9       | 729/2445 [07:43<18:22,  1.56it/s]
em: 0.2910, f1: 0.3487, loss: 4.1238 ||:  31%|###       | 746/2445 [07:54<18:02,  1.57it/s]
em: 0.2920, f1: 0.3496, loss: 4.1195 ||:  31%|###1      | 762/2445 [08:05<18:03,  1.55it/s]
em: 0.2912, f1: 0.3486, loss: 4.1227 ||:  32%|###1      | 779/2445 [08:15<17:25,  1.59it/s]
em: 0.2913, f1: 0.3488, loss: 4.1327 ||:  33%|###2      | 796/2445 [08:26<17:21,  1.58it/s]
em: 0.2907, f1: 0.3487, loss: 4.1283 ||:  33%|###3      | 812/2445 [08:36<17:14,  1.58it/s]
em: 0.2902, f1: 0.3486, loss: 4.1268 ||:  34%|###3      | 828/2445 [08:46<17:15,  1.56it/s]
em: 0.2901, f1: 0.3485, loss: 4.1260 ||:  35%|###4      | 844/2445 [08:57<17:21,  1.54it/s]
em: 0.2898, f1: 0.3481, loss: 4.1207 ||:  35%|###5      | 860/2445 [09:08<17:14,  1.53it/s]
em: 0.2901, f1: 0.3483, loss: 4.1159 ||:  36%|###5      | 876/2445 [09:18<17:13,  1.52it/s]
em: 0.2906, f1: 0.3489, loss: 4.1181 ||:  37%|###6      | 893/2445 [09:29<16:43,  1.55it/s]
em: 0.2907, f1: 0.3490, loss: 4.1165 ||:  37%|###7      | 910/2445 [09:40<16:30,  1.55it/s]
em: 0.2893, f1: 0.3478, loss: 4.1220 ||:  38%|###7      | 926/2445 [09:50<16:16,  1.56it/s]
em: 0.2895, f1: 0.3479, loss: 4.1186 ||:  39%|###8      | 942/2445 [10:01<16:14,  1.54it/s]
em: 0.2893, f1: 0.3475, loss: 4.1193 ||:  39%|###9      | 958/2445 [10:11<16:07,  1.54it/s]
em: 0.2889, f1: 0.3472, loss: 4.1224 ||:  40%|###9      | 975/2445 [10:21<15:38,  1.57it/s]
em: 0.2882, f1: 0.3466, loss: 4.1238 ||:  41%|####      | 992/2445 [10:32<15:30,  1.56it/s]
em: 0.2886, f1: 0.3468, loss: 4.1236 ||:  41%|####1     | 1008/2445 [10:42<15:14,  1.57it/s]
em: 0.2888, f1: 0.3470, loss: 4.1201 ||:  42%|####1     | 1024/2445 [10:53<15:05,  1.57it/s]
em: 0.2875, f1: 0.3459, loss: 4.1219 ||:  43%|####2     | 1040/2445 [11:03<15:02,  1.56it/s]
em: 0.2874, f1: 0.3457, loss: 4.1180 ||:  43%|####3     | 1056/2445 [11:13<14:52,  1.56it/s]
em: 0.2876, f1: 0.3459, loss: 4.1178 ||:  44%|####3     | 1073/2445 [11:24<14:30,  1.58it/s]
em: 0.2880, f1: 0.3465, loss: 4.1136 ||:  45%|####4     | 1090/2445 [11:34<14:10,  1.59it/s]
em: 0.2880, f1: 0.3464, loss: 4.1170 ||:  45%|####5     | 1107/2445 [11:45<14:10,  1.57it/s]
em: 0.2878, f1: 0.3462, loss: 4.1172 ||:  46%|####5     | 1123/2445 [11:56<14:04,  1.56it/s]
em: 0.2870, f1: 0.3455, loss: 4.1183 ||:  47%|####6     | 1139/2445 [12:06<13:49,  1.57it/s]
em: 0.2877, f1: 0.3462, loss: 4.1150 ||:  47%|####7     | 1155/2445 [12:16<13:48,  1.56it/s]
em: 0.2885, f1: 0.3472, loss: 4.1103 ||:  48%|####7     | 1171/2445 [12:27<13:38,  1.56it/s]
em: 0.2884, f1: 0.3471, loss: 4.1083 ||:  49%|####8     | 1188/2445 [12:37<13:22,  1.57it/s]
em: 0.2877, f1: 0.3465, loss: 4.1111 ||:  49%|####9     | 1204/2445 [12:48<13:18,  1.56it/s]
em: 0.2879, f1: 0.3469, loss: 4.1090 ||:  50%|####9     | 1220/2445 [12:58<13:13,  1.54it/s]
em: 0.2881, f1: 0.3472, loss: 4.1102 ||:  51%|#####     | 1236/2445 [13:09<13:05,  1.54it/s]
em: 0.2879, f1: 0.3472, loss: 4.1155 ||:  51%|#####1    | 1253/2445 [13:19<12:37,  1.57it/s]
em: 0.2879, f1: 0.3474, loss: 4.1113 ||:  52%|#####1    | 1270/2445 [13:30<12:37,  1.55it/s]
em: 0.2888, f1: 0.3482, loss: 4.1092 ||:  53%|#####2    | 1286/2445 [13:40<12:21,  1.56it/s]
em: 0.2891, f1: 0.3484, loss: 4.1067 ||:  53%|#####3    | 1302/2445 [13:51<12:14,  1.56it/s]
em: 0.2895, f1: 0.3487, loss: 4.1015 ||:  54%|#####3    | 1318/2445 [14:01<12:02,  1.56it/s]
em: 0.2906, f1: 0.3497, loss: 4.0962 ||:  55%|#####4    | 1335/2445 [14:11<11:39,  1.59it/s]
em: 0.2911, f1: 0.3504, loss: 4.0919 ||:  55%|#####5    | 1352/2445 [14:21<11:14,  1.62it/s]
em: 0.2914, f1: 0.3507, loss: 4.0901 ||:  56%|#####5    | 1369/2445 [14:32<11:12,  1.60it/s]
em: 0.2909, f1: 0.3502, loss: 4.0907 ||:  57%|#####6    | 1385/2445 [14:42<11:05,  1.59it/s]
em: 0.2909, f1: 0.3501, loss: 4.0896 ||:  57%|#####7    | 1401/2445 [14:52<10:54,  1.59it/s]
em: 0.2909, f1: 0.3501, loss: 4.0886 ||:  58%|#####7    | 1417/2445 [15:03<10:50,  1.58it/s]
em: 0.2911, f1: 0.3504, loss: 4.0912 ||:  59%|#####8    | 1433/2445 [15:13<10:47,  1.56it/s]
em: 0.2916, f1: 0.3510, loss: 4.0898 ||:  59%|#####9    | 1449/2445 [15:24<10:43,  1.55it/s]
em: 0.2915, f1: 0.3512, loss: 4.0889 ||:  60%|#####9    | 1466/2445 [15:34<10:16,  1.59it/s]
em: 0.2911, f1: 0.3509, loss: 4.0892 ||:  61%|######    | 1483/2445 [15:45<10:09,  1.58it/s]
em: 0.2918, f1: 0.3515, loss: 4.0822 ||:  61%|######1   | 1500/2445 [15:55<09:54,  1.59it/s]
em: 0.2923, f1: 0.3520, loss: 4.0797 ||:  62%|######2   | 1517/2445 [16:05<09:35,  1.61it/s]
em: 0.2929, f1: 0.3525, loss: 4.0781 ||:  63%|######2   | 1534/2445 [16:16<09:31,  1.59it/s]
em: 0.2929, f1: 0.3523, loss: 4.0745 ||:  63%|######3   | 1550/2445 [16:27<09:25,  1.58it/s]
em: 0.2936, f1: 0.3531, loss: 4.0673 ||:  64%|######4   | 1566/2445 [16:37<09:22,  1.56it/s]
em: 0.2933, f1: 0.3529, loss: 4.0665 ||:  65%|######4   | 1582/2445 [16:48<09:16,  1.55it/s]
em: 0.2935, f1: 0.3529, loss: 4.0645 ||:  65%|######5   | 1599/2445 [16:58<08:55,  1.58it/s]
em: 0.2935, f1: 0.3530, loss: 4.0654 ||:  66%|######6   | 1616/2445 [17:09<08:44,  1.58it/s]
em: 0.2939, f1: 0.3533, loss: 4.0647 ||:  67%|######6   | 1632/2445 [17:19<08:33,  1.58it/s]
em: 0.2935, f1: 0.3533, loss: 4.0645 ||:  67%|######7   | 1648/2445 [17:29<08:30,  1.56it/s]
em: 0.2932, f1: 0.3532, loss: 4.0645 ||:  68%|######8   | 1664/2445 [17:39<08:17,  1.57it/s]
em: 0.2944, f1: 0.3543, loss: 4.0601 ||:  69%|######8   | 1680/2445 [17:50<08:14,  1.55it/s]
em: 0.2952, f1: 0.3554, loss: 4.0547 ||:  69%|######9   | 1697/2445 [18:00<07:53,  1.58it/s]
em: 0.2959, f1: 0.3561, loss: 4.0496 ||:  70%|#######   | 1714/2445 [18:11<07:44,  1.57it/s]
em: 0.2953, f1: 0.3555, loss: 4.0567 ||:  71%|#######   | 1730/2445 [18:22<07:37,  1.56it/s]
em: 0.2959, f1: 0.3561, loss: 4.0579 ||:  71%|#######1  | 1747/2445 [18:32<07:22,  1.58it/s]
em: 0.2959, f1: 0.3561, loss: 4.0600 ||:  72%|#######2  | 1764/2445 [18:43<07:13,  1.57it/s]
em: 0.2966, f1: 0.3568, loss: 4.0608 ||:  73%|#######2  | 1780/2445 [18:53<07:04,  1.56it/s]
em: 0.2969, f1: 0.3572, loss: 4.0590 ||:  73%|#######3  | 1797/2445 [19:04<06:51,  1.58it/s]
em: 0.2970, f1: 0.3572, loss: 4.0577 ||:  74%|#######4  | 1814/2445 [19:15<06:37,  1.59it/s]
em: 0.2970, f1: 0.3572, loss: 4.0575 ||:  75%|#######4  | 1831/2445 [19:26<06:32,  1.56it/s]
em: 0.2973, f1: 0.3574, loss: 4.0563 ||:  76%|#######5  | 1847/2445 [19:36<06:23,  1.56it/s]
em: 0.2981, f1: 0.3582, loss: 4.0512 ||:  76%|#######6  | 1863/2445 [19:47<06:16,  1.55it/s]
em: 0.2987, f1: 0.3588, loss: 4.0470 ||:  77%|#######6  | 1879/2445 [19:57<06:04,  1.55it/s]
em: 0.2987, f1: 0.3588, loss: 4.0462 ||:  78%|#######7  | 1896/2445 [20:07<05:49,  1.57it/s]
em: 0.2989, f1: 0.3589, loss: 4.0430 ||:  78%|#######8  | 1913/2445 [20:18<05:36,  1.58it/s]
em: 0.2990, f1: 0.3590, loss: 4.0384 ||:  79%|#######8  | 1930/2445 [20:28<05:22,  1.60it/s]
em: 0.2995, f1: 0.3595, loss: 4.0376 ||:  80%|#######9  | 1947/2445 [20:40<05:16,  1.57it/s]
em: 0.3001, f1: 0.3601, loss: 4.0367 ||:  80%|########  | 1964/2445 [20:50<05:00,  1.60it/s]
em: 0.3002, f1: 0.3602, loss: 4.0378 ||:  81%|########1 | 1981/2445 [21:01<04:51,  1.59it/s]
em: 0.3006, f1: 0.3604, loss: 4.0342 ||:  82%|########1 | 1997/2445 [21:11<04:41,  1.59it/s]
em: 0.3010, f1: 0.3607, loss: 4.0327 ||:  82%|########2 | 2014/2445 [21:21<04:29,  1.60it/s]
em: 0.3009, f1: 0.3608, loss: 4.0336 ||:  83%|########3 | 2031/2445 [21:33<04:25,  1.56it/s]
em: 0.3011, f1: 0.3612, loss: 4.0328 ||:  84%|########3 | 2048/2445 [21:43<04:11,  1.58it/s]
em: 0.3019, f1: 0.3622, loss: 4.0301 ||:  84%|########4 | 2065/2445 [21:54<04:01,  1.57it/s]
em: 0.3020, f1: 0.3622, loss: 4.0290 ||:  85%|########5 | 2081/2445 [22:04<03:52,  1.57it/s]
em: 0.3019, f1: 0.3624, loss: 4.0308 ||:  86%|########5 | 2097/2445 [22:15<03:45,  1.54it/s]
em: 0.3021, f1: 0.3624, loss: 4.0283 ||:  86%|########6 | 2114/2445 [22:26<03:31,  1.57it/s]
em: 0.3028, f1: 0.3631, loss: 4.0257 ||:  87%|########7 | 2131/2445 [22:37<03:23,  1.55it/s]
em: 0.3030, f1: 0.3633, loss: 4.0274 ||:  88%|########7 | 2147/2445 [22:47<03:11,  1.55it/s]
em: 0.3030, f1: 0.3634, loss: 4.0272 ||:  88%|########8 | 2163/2445 [22:57<03:01,  1.56it/s]
em: 0.3036, f1: 0.3641, loss: 4.0227 ||:  89%|########9 | 2180/2445 [23:08<02:48,  1.58it/s]
em: 0.3036, f1: 0.3644, loss: 4.0193 ||:  90%|########9 | 2197/2445 [23:18<02:36,  1.58it/s]
em: 0.3033, f1: 0.3641, loss: 4.0181 ||:  91%|######### | 2213/2445 [23:29<02:28,  1.56it/s]
em: 0.3036, f1: 0.3644, loss: 4.0165 ||:  91%|#########1| 2229/2445 [23:39<02:19,  1.55it/s]
em: 0.3036, f1: 0.3645, loss: 4.0164 ||:  92%|#########1| 2245/2445 [23:50<02:08,  1.56it/s]
em: 0.3036, f1: 0.3646, loss: 4.0157 ||:  92%|#########2| 2261/2445 [24:00<01:58,  1.55it/s]
em: 0.3037, f1: 0.3647, loss: 4.0153 ||:  93%|#########3| 2277/2445 [24:10<01:47,  1.56it/s]
em: 0.3037, f1: 0.3649, loss: 4.0131 ||:  94%|#########3| 2293/2445 [24:21<01:37,  1.55it/s]
em: 0.3037, f1: 0.3650, loss: 4.0115 ||:  94%|#########4| 2309/2445 [24:31<01:27,  1.55it/s]
em: 0.3034, f1: 0.3648, loss: 4.0094 ||:  95%|#########5| 2325/2445 [24:42<01:18,  1.54it/s]
em: 0.3033, f1: 0.3648, loss: 4.0075 ||:  96%|#########5| 2342/2445 [24:52<01:05,  1.57it/s]
em: 0.3028, f1: 0.3644, loss: 4.0080 ||:  96%|#########6| 2359/2445 [25:03<00:55,  1.55it/s]
em: 0.3025, f1: 0.3641, loss: 4.0076 ||:  97%|#########7| 2375/2445 [25:13<00:44,  1.56it/s]
em: 0.3018, f1: 0.3637, loss: 4.0082 ||:  98%|#########7| 2391/2445 [25:23<00:34,  1.56it/s]
em: 0.3013, f1: 0.3634, loss: 4.0068 ||:  98%|#########8| 2407/2445 [25:34<00:24,  1.54it/s]
em: 0.3007, f1: 0.3629, loss: 4.0058 ||:  99%|#########9| 2424/2445 [25:45<00:13,  1.57it/s]
em: 0.3000, f1: 0.3624, loss: 4.0071 ||: 100%|#########9| 2441/2445 [25:55<00:02,  1.57it/s]
em: 0.2998, f1: 0.3622, loss: 4.0050 ||: : 2458it [26:06,  1.58it/s]                        
em: 0.2991, f1: 0.3617, loss: 4.0049 ||: : 2475it [26:17,  1.58it/s]
em: 0.2990, f1: 0.3616, loss: 4.0051 ||: : 2478it [26:18,  1.57it/s]

2019-05-10 08:10:09,469 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/596 [00:00<?, ?it/s]
em: 0.2778, f1: 0.3071, loss: 4189816.1528 ||:   5%|4         | 27/596 [00:10<03:42,  2.55it/s]
em: 0.2607, f1: 0.2910, loss: 4481133.3514 ||:   9%|8         | 53/596 [00:25<04:00,  2.26it/s]
em: 0.2624, f1: 0.2959, loss: 4480635.2095 ||:  12%|#1        | 71/596 [00:35<04:16,  2.04it/s]
em: 0.2595, f1: 0.2925, loss: 4469087.4503 ||:  16%|#5        | 93/596 [00:46<04:03,  2.06it/s]
em: 0.2693, f1: 0.3003, loss: 4554349.1424 ||:  19%|#9        | 115/596 [00:59<04:10,  1.92it/s]
em: 0.2514, f1: 0.2840, loss: 4736608.4188 ||:  23%|##3       | 140/596 [01:09<03:41,  2.05it/s]
em: 0.2412, f1: 0.2728, loss: 4784092.2053 ||:  28%|##7       | 165/596 [01:24<03:40,  1.95it/s]
em: 0.2342, f1: 0.2658, loss: 4816577.3852 ||:  31%|###       | 184/596 [01:34<03:36,  1.90it/s]
em: 0.2307, f1: 0.2614, loss: 4896845.9217 ||:  35%|###4      | 206/596 [01:44<03:17,  1.98it/s]
em: 0.2283, f1: 0.2607, loss: 4841010.0828 ||:  38%|###8      | 228/596 [01:57<03:14,  1.89it/s]
em: 0.2337, f1: 0.2652, loss: 4838790.9747 ||:  42%|####2     | 252/596 [02:07<02:50,  2.01it/s]
em: 0.2360, f1: 0.2674, loss: 4834693.3438 ||:  46%|####6     | 276/596 [02:21<02:45,  1.94it/s]
em: 0.2368, f1: 0.2674, loss: 4845862.7876 ||:  50%|####9     | 296/596 [02:31<02:35,  1.93it/s]
em: 0.2347, f1: 0.2642, loss: 4868318.9026 ||:  53%|#####3    | 318/596 [02:41<02:18,  2.00it/s]
em: 0.2338, f1: 0.2632, loss: 4856618.9295 ||:  57%|#####7    | 340/596 [02:56<02:21,  1.81it/s]
em: 0.2370, f1: 0.2660, loss: 4854053.4634 ||:  61%|######1   | 364/596 [03:06<01:59,  1.95it/s]
em: 0.2392, f1: 0.2684, loss: 4824421.3999 ||:  65%|######5   | 388/596 [03:20<01:51,  1.87it/s]
em: 0.2387, f1: 0.2666, loss: 4836492.7424 ||:  69%|######8   | 409/596 [03:30<01:36,  1.93it/s]
em: 0.2381, f1: 0.2661, loss: 4829943.1729 ||:  72%|#######2  | 430/596 [03:41<01:26,  1.93it/s]
em: 0.2371, f1: 0.2653, loss: 4837501.3152 ||:  76%|#######5  | 450/596 [03:53<01:18,  1.87it/s]
em: 0.2324, f1: 0.2606, loss: 4894069.0706 ||:  79%|#######9  | 472/596 [04:03<01:03,  1.95it/s]
em: 0.2285, f1: 0.2567, loss: 4945598.4000 ||:  83%|########2 | 494/596 [04:14<00:51,  1.97it/s]
em: 0.2258, f1: 0.2545, loss: 4961833.2673 ||:  88%|########7 | 524/596 [04:24<00:32,  2.19it/s]
em: 0.2241, f1: 0.2521, loss: 5000001.1749 ||:  93%|#########2| 554/596 [04:36<00:18,  2.25it/s]
em: 0.2182, f1: 0.2463, loss: 5069085.7783 ||:  97%|#########7| 579/596 [04:49<00:07,  2.15it/s]
em: 0.2148, f1: 0.2432, loss: 5097037.8650 ||: : 599it [05:01,  2.01it/s]                       
em: 0.2142, f1: 0.2427, loss: 5102443.1931 ||: : 604it [05:05,  1.98it/s]

2019-05-10 08:15:14,752 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2019-05-10 08:15:14,753 - INFO - allennlp.training.tensorboard_writer - loss            |     4.005  |  5102443.193
2019-05-10 08:15:14,753 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4561.000  |       N/A
2019-05-10 08:15:14,753 - INFO - allennlp.training.tensorboard_writer - em              |     0.299  |     0.214
2019-05-10 08:15:14,753 - INFO - allennlp.training.tensorboard_writer - f1              |     0.362  |     0.243
2019-05-10 08:15:14,754 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6474.356  |       N/A
2019-05-10 08:15:57,121 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'out/rc_bert_simple_v2/best.th'.
2019-05-10 08:16:39,043 - INFO - allennlp.training.trainer - Epoch duration: 00:32:48
2019-05-10 08:16:39,044 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:32:09
2019-05-10 08:16:39,044 - INFO - allennlp.training.trainer - Epoch 2/9
2019-05-10 08:16:39,044 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6476.352
2019-05-10 08:16:39,169 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 4561
2019-05-10 08:16:39,176 - INFO - allennlp.training.trainer - Training
  0%|          | 0/2445 [00:00<?, ?it/s]
em: 0.3713, f1: 0.4392, loss: 3.2790 ||:   1%|          | 17/2445 [00:10<25:09,  1.61it/s]
em: 0.3843, f1: 0.4453, loss: 3.2183 ||:   1%|1         | 34/2445 [00:21<24:58,  1.61it/s]
em: 0.3676, f1: 0.4250, loss: 3.4186 ||:   2%|2         | 51/2445 [00:32<25:02,  1.59it/s]
em: 0.3409, f1: 0.4037, loss: 3.6196 ||:   3%|2         | 67/2445 [00:42<24:53,  1.59it/s]
em: 0.3293, f1: 0.3968, loss: 3.6336 ||:   3%|3         | 83/2445 [00:52<24:41,  1.59it/s]
em: 0.3367, f1: 0.4079, loss: 3.5911 ||:   4%|4         | 99/2445 [01:02<24:34,  1.59it/s]
em: 0.3403, f1: 0.4096, loss: 3.5645 ||:   5%|4         | 115/2445 [01:12<24:42,  1.57it/s]
em: 0.3429, f1: 0.4106, loss: 3.5789 ||:   5%|5         | 132/2445 [01:23<24:17,  1.59it/s]
em: 0.3444, f1: 0.4122, loss: 3.5552 ||:   6%|6         | 149/2445 [01:33<24:06,  1.59it/s]
em: 0.3527, f1: 0.4201, loss: 3.5397 ||:   7%|6         | 165/2445 [01:44<24:02,  1.58it/s]
em: 0.3569, f1: 0.4232, loss: 3.5587 ||:   7%|7         | 182/2445 [01:54<23:39,  1.59it/s]
em: 0.3578, f1: 0.4234, loss: 3.5628 ||:   8%|8         | 199/2445 [02:05<23:54,  1.57it/s]
em: 0.3506, f1: 0.4179, loss: 3.5922 ||:   9%|8         | 216/2445 [02:16<23:38,  1.57it/s]
em: 0.3483, f1: 0.4146, loss: 3.6137 ||:   9%|9         | 232/2445 [02:27<23:41,  1.56it/s]
em: 0.3497, f1: 0.4151, loss: 3.6188 ||:  10%|#         | 248/2445 [02:37<23:45,  1.54it/s]
em: 0.3533, f1: 0.4186, loss: 3.6010 ||:  11%|#         | 265/2445 [02:48<23:12,  1.57it/s]
em: 0.3546, f1: 0.4207, loss: 3.5989 ||:  12%|#1        | 282/2445 [02:58<22:58,  1.57it/s]
em: 0.3574, f1: 0.4225, loss: 3.5962 ||:  12%|#2        | 298/2445 [03:09<22:53,  1.56it/s]
em: 0.3551, f1: 0.4206, loss: 3.5965 ||:  13%|#2        | 315/2445 [03:19<22:29,  1.58it/s]
em: 0.3567, f1: 0.4216, loss: 3.5746 ||:  14%|#3        | 332/2445 [03:30<22:17,  1.58it/s]
em: 0.3566, f1: 0.4209, loss: 3.5723 ||:  14%|#4        | 348/2445 [03:40<22:21,  1.56it/s]
em: 0.3562, f1: 0.4209, loss: 3.5751 ||:  15%|#4        | 364/2445 [03:51<22:19,  1.55it/s]
em: 0.3560, f1: 0.4204, loss: 3.5828 ||:  16%|#5        | 380/2445 [04:01<22:00,  1.56it/s]
em: 0.3558, f1: 0.4199, loss: 3.5685 ||:  16%|#6        | 397/2445 [04:11<21:29,  1.59it/s]
em: 0.3560, f1: 0.4199, loss: 3.5779 ||:  17%|#6        | 414/2445 [04:22<21:12,  1.60it/s]
em: 0.3587, f1: 0.4223, loss: 3.5734 ||:  18%|#7        | 431/2445 [04:33<21:18,  1.57it/s]
em: 0.3562, f1: 0.4196, loss: 3.5781 ||:  18%|#8        | 447/2445 [04:43<21:16,  1.57it/s]
em: 0.3551, f1: 0.4187, loss: 3.5856 ||:  19%|#8        | 464/2445 [04:54<20:43,  1.59it/s]
em: 0.3527, f1: 0.4171, loss: 3.6062 ||:  20%|#9        | 481/2445 [05:05<20:47,  1.57it/s]
em: 0.3522, f1: 0.4166, loss: 3.6155 ||:  20%|##        | 498/2445 [05:15<20:24,  1.59it/s]
em: 0.3493, f1: 0.4141, loss: 3.6248 ||:  21%|##1       | 515/2445 [05:26<20:20,  1.58it/s]
em: 0.3493, f1: 0.4142, loss: 3.6320 ||:  22%|##1       | 533/2445 [05:37<19:51,  1.61it/s]
em: 0.3501, f1: 0.4154, loss: 3.6277 ||:  22%|##2       | 550/2445 [05:47<19:34,  1.61it/s]
em: 0.3512, f1: 0.4166, loss: 3.6238 ||:  23%|##3       | 567/2445 [05:58<19:38,  1.59it/s]
em: 0.3515, f1: 0.4167, loss: 3.6371 ||:  24%|##3       | 583/2445 [06:09<20:02,  1.55it/s]
em: 0.3526, f1: 0.4173, loss: 3.6329 ||:  25%|##4       | 600/2445 [06:19<19:25,  1.58it/s]
em: 0.3526, f1: 0.4172, loss: 3.6387 ||:  25%|##5       | 617/2445 [06:30<19:14,  1.58it/s]
em: 0.3537, f1: 0.4180, loss: 3.6433 ||:  26%|##5       | 634/2445 [06:41<19:01,  1.59it/s]
em: 0.3546, f1: 0.4187, loss: 3.6447 ||:  27%|##6       | 650/2445 [06:51<18:53,  1.58it/s]
em: 0.3546, f1: 0.4186, loss: 3.6508 ||:  27%|##7       | 666/2445 [07:01<18:54,  1.57it/s]
em: 0.3530, f1: 0.4172, loss: 3.6578 ||:  28%|##7       | 682/2445 [07:12<18:42,  1.57it/s]
em: 0.3517, f1: 0.4157, loss: 3.6523 ||:  29%|##8       | 698/2445 [07:22<18:38,  1.56it/s]
em: 0.3523, f1: 0.4165, loss: 3.6496 ||:  29%|##9       | 715/2445 [07:33<18:19,  1.57it/s]
em: 0.3527, f1: 0.4168, loss: 3.6451 ||:  30%|##9       | 732/2445 [07:44<18:17,  1.56it/s]
em: 0.3534, f1: 0.4174, loss: 3.6421 ||:  31%|###       | 748/2445 [07:54<18:12,  1.55it/s]
em: 0.3531, f1: 0.4168, loss: 3.6453 ||:  31%|###1      | 764/2445 [08:04<18:03,  1.55it/s]
em: 0.3517, f1: 0.4156, loss: 3.6565 ||:  32%|###1      | 780/2445 [08:14<17:44,  1.56it/s]
em: 0.3520, f1: 0.4160, loss: 3.6563 ||:  33%|###2      | 797/2445 [08:25<17:17,  1.59it/s]
em: 0.3514, f1: 0.4155, loss: 3.6530 ||:  33%|###3      | 814/2445 [08:36<17:21,  1.57it/s]
em: 0.3508, f1: 0.4158, loss: 3.6495 ||:  34%|###3      | 831/2445 [08:46<16:56,  1.59it/s]
em: 0.3506, f1: 0.4155, loss: 3.6464 ||:  35%|###4      | 848/2445 [08:58<17:13,  1.54it/s]
em: 0.3500, f1: 0.4150, loss: 3.6475 ||:  35%|###5      | 864/2445 [09:08<16:59,  1.55it/s]
em: 0.3506, f1: 0.4154, loss: 3.6475 ||:  36%|###5      | 880/2445 [09:19<16:56,  1.54it/s]
em: 0.3503, f1: 0.4153, loss: 3.6484 ||:  37%|###6      | 896/2445 [09:29<16:36,  1.55it/s]
em: 0.3509, f1: 0.4158, loss: 3.6463 ||:  37%|###7      | 912/2445 [09:39<16:28,  1.55it/s]
em: 0.3508, f1: 0.4156, loss: 3.6445 ||:  38%|###7      | 928/2445 [09:49<16:09,  1.56it/s]
em: 0.3514, f1: 0.4162, loss: 3.6440 ||:  39%|###8      | 944/2445 [10:00<16:08,  1.55it/s]
em: 0.3506, f1: 0.4153, loss: 3.6453 ||:  39%|###9      | 960/2445 [10:10<16:00,  1.55it/s]
em: 0.3508, f1: 0.4155, loss: 3.6485 ||:  40%|###9      | 977/2445 [10:21<15:36,  1.57it/s]
em: 0.3500, f1: 0.4147, loss: 3.6560 ||:  41%|####      | 994/2445 [10:31<15:15,  1.58it/s]
em: 0.3499, f1: 0.4150, loss: 3.6521 ||:  41%|####1     | 1011/2445 [10:42<14:57,  1.60it/s]
em: 0.3512, f1: 0.4159, loss: 3.6477 ||:  42%|####2     | 1028/2445 [10:53<15:05,  1.57it/s]
em: 0.3506, f1: 0.4154, loss: 3.6446 ||:  43%|####2     | 1044/2445 [11:03<14:54,  1.57it/s]
em: 0.3506, f1: 0.4160, loss: 3.6406 ||:  43%|####3     | 1060/2445 [11:13<14:44,  1.57it/s]
em: 0.3507, f1: 0.4161, loss: 3.6445 ||:  44%|####4     | 1076/2445 [11:24<14:37,  1.56it/s]
em: 0.3509, f1: 0.4167, loss: 3.6478 ||:  45%|####4     | 1093/2445 [11:34<14:07,  1.60it/s]
em: 0.3502, f1: 0.4160, loss: 3.6474 ||:  45%|####5     | 1110/2445 [11:45<14:04,  1.58it/s]
em: 0.3495, f1: 0.4153, loss: 3.6489 ||:  46%|####6     | 1126/2445 [11:55<14:00,  1.57it/s]
em: 0.3496, f1: 0.4156, loss: 3.6422 ||:  47%|####6     | 1143/2445 [12:06<13:44,  1.58it/s]
em: 0.3499, f1: 0.4158, loss: 3.6411 ||:  47%|####7     | 1159/2445 [12:17<13:51,  1.55it/s]
em: 0.3498, f1: 0.4157, loss: 3.6422 ||:  48%|####8     | 1175/2445 [12:27<13:35,  1.56it/s]
em: 0.3502, f1: 0.4163, loss: 3.6430 ||:  49%|####8     | 1191/2445 [12:37<13:34,  1.54it/s]
em: 0.3498, f1: 0.4157, loss: 3.6423 ||:  49%|####9     | 1208/2445 [12:48<13:11,  1.56it/s]
em: 0.3488, f1: 0.4146, loss: 3.6479 ||:  50%|#####     | 1225/2445 [12:59<13:01,  1.56it/s]
em: 0.3487, f1: 0.4145, loss: 3.6522 ||:  51%|#####     | 1242/2445 [13:09<12:44,  1.57it/s]
em: 0.3487, f1: 0.4146, loss: 3.6494 ||:  51%|#####1    | 1259/2445 [13:21<12:42,  1.56it/s]
em: 0.3485, f1: 0.4144, loss: 3.6499 ||:  52%|#####2    | 1276/2445 [13:31<12:26,  1.57it/s]
em: 0.3483, f1: 0.4143, loss: 3.6506 ||:  53%|#####2    | 1292/2445 [13:42<12:16,  1.56it/s]
em: 0.3487, f1: 0.4143, loss: 3.6461 ||:  53%|#####3    | 1308/2445 [13:52<12:03,  1.57it/s]
em: 0.3480, f1: 0.4141, loss: 3.6439 ||:  54%|#####4    | 1325/2445 [14:02<11:42,  1.59it/s]
em: 0.3490, f1: 0.4146, loss: 3.6413 ||:  55%|#####4    | 1342/2445 [14:13<11:35,  1.59it/s]
em: 0.3488, f1: 0.4146, loss: 3.6373 ||:  56%|#####5    | 1359/2445 [14:23<11:18,  1.60it/s]
em: 0.3486, f1: 0.4146, loss: 3.6371 ||:  56%|#####6    | 1376/2445 [14:34<11:10,  1.59it/s]
em: 0.3484, f1: 0.4144, loss: 3.6399 ||:  57%|#####6    | 1392/2445 [14:44<11:00,  1.60it/s]
em: 0.3482, f1: 0.4143, loss: 3.6403 ||:  58%|#####7    | 1408/2445 [14:54<10:56,  1.58it/s]
em: 0.3481, f1: 0.4141, loss: 3.6417 ||:  58%|#####8    | 1424/2445 [15:05<10:52,  1.57it/s]
em: 0.3478, f1: 0.4139, loss: 3.6431 ||:  59%|#####8    | 1440/2445 [15:15<10:44,  1.56it/s]
em: 0.3478, f1: 0.4140, loss: 3.6411 ||:  60%|#####9    | 1457/2445 [15:26<10:27,  1.57it/s]
em: 0.3473, f1: 0.4135, loss: 3.6423 ||:  60%|######    | 1474/2445 [15:36<10:08,  1.60it/s]
em: 0.3473, f1: 0.4135, loss: 3.6403 ||:  61%|######    | 1491/2445 [15:47<10:04,  1.58it/s]
em: 0.3475, f1: 0.4136, loss: 3.6362 ||:  62%|######1   | 1508/2445 [15:58<09:49,  1.59it/s]
em: 0.3472, f1: 0.4134, loss: 3.6356 ||:  62%|######2   | 1525/2445 [16:08<09:36,  1.60it/s]
em: 0.3476, f1: 0.4136, loss: 3.6328 ||:  63%|######3   | 1542/2445 [16:19<09:32,  1.58it/s]
em: 0.3475, f1: 0.4136, loss: 3.6301 ||:  64%|######3   | 1558/2445 [16:29<09:21,  1.58it/s]
em: 0.3469, f1: 0.4127, loss: 3.6319 ||:  64%|######4   | 1574/2445 [16:40<09:14,  1.57it/s]
em: 0.3470, f1: 0.4127, loss: 3.6289 ||:  65%|######5   | 1590/2445 [16:50<09:03,  1.57it/s]
em: 0.3469, f1: 0.4127, loss: 3.6288 ||:  66%|######5   | 1607/2445 [17:00<08:49,  1.58it/s]
em: 0.3472, f1: 0.4129, loss: 3.6265 ||:  66%|######6   | 1624/2445 [17:11<08:33,  1.60it/s]
em: 0.3471, f1: 0.4126, loss: 3.6287 ||:  67%|######7   | 1641/2445 [17:22<08:33,  1.57it/s]
em: 0.3468, f1: 0.4124, loss: 3.6301 ||:  68%|######7   | 1656/2445 [17:32<08:30,  1.55it/s]
em: 0.3466, f1: 0.4124, loss: 3.6291 ||:  68%|######8   | 1672/2445 [17:42<08:17,  1.55it/s]
em: 0.3468, f1: 0.4126, loss: 3.6274 ||:  69%|######9   | 1688/2445 [17:53<08:10,  1.54it/s]
em: 0.3475, f1: 0.4135, loss: 3.6232 ||:  70%|######9   | 1705/2445 [18:03<07:50,  1.57it/s]
em: 0.3471, f1: 0.4132, loss: 3.6260 ||:  70%|#######   | 1722/2445 [18:14<07:43,  1.56it/s]
em: 0.3472, f1: 0.4132, loss: 3.6319 ||:  71%|#######1  | 1738/2445 [18:24<07:31,  1.57it/s]
em: 0.3470, f1: 0.4131, loss: 3.6345 ||:  72%|#######1  | 1754/2445 [18:35<07:22,  1.56it/s]
em: 0.3477, f1: 0.4137, loss: 3.6356 ||:  72%|#######2  | 1770/2445 [18:45<07:11,  1.57it/s]
em: 0.3480, f1: 0.4138, loss: 3.6363 ||:  73%|#######3  | 1786/2445 [18:55<06:58,  1.57it/s]
em: 0.3483, f1: 0.4140, loss: 3.6339 ||:  74%|#######3  | 1802/2445 [19:05<06:51,  1.56it/s]
em: 0.3487, f1: 0.4143, loss: 3.6345 ||:  74%|#######4  | 1819/2445 [19:16<06:34,  1.59it/s]
em: 0.3491, f1: 0.4146, loss: 3.6328 ||:  75%|#######5  | 1836/2445 [19:27<06:29,  1.56it/s]
em: 0.3492, f1: 0.4147, loss: 3.6316 ||:  76%|#######5  | 1852/2445 [19:37<06:18,  1.57it/s]
em: 0.3493, f1: 0.4147, loss: 3.6298 ||:  76%|#######6  | 1868/2445 [19:48<06:13,  1.54it/s]
em: 0.3496, f1: 0.4149, loss: 3.6251 ||:  77%|#######7  | 1885/2445 [19:58<05:58,  1.56it/s]
em: 0.3500, f1: 0.4152, loss: 3.6252 ||:  78%|#######7  | 1902/2445 [20:09<05:47,  1.56it/s]
em: 0.3505, f1: 0.4156, loss: 3.6217 ||:  78%|#######8  | 1919/2445 [20:20<05:31,  1.58it/s]
em: 0.3506, f1: 0.4156, loss: 3.6199 ||:  79%|#######9  | 1936/2445 [20:30<05:18,  1.60it/s]
em: 0.3505, f1: 0.4153, loss: 3.6214 ||:  80%|#######9  | 1953/2445 [20:41<05:06,  1.60it/s]
em: 0.3506, f1: 0.4153, loss: 3.6234 ||:  81%|########  | 1970/2445 [20:51<04:57,  1.60it/s]
em: 0.3504, f1: 0.4150, loss: 3.6227 ||:  81%|########1 | 1987/2445 [21:02<04:44,  1.61it/s]
em: 0.3506, f1: 0.4152, loss: 3.6232 ||:  82%|########1 | 2004/2445 [21:12<04:34,  1.61it/s]
em: 0.3503, f1: 0.4148, loss: 3.6224 ||:  83%|########2 | 2021/2445 [21:23<04:28,  1.58it/s]
em: 0.3503, f1: 0.4149, loss: 3.6235 ||:  83%|########3 | 2037/2445 [21:33<04:17,  1.58it/s]
em: 0.3499, f1: 0.4146, loss: 3.6267 ||:  84%|########3 | 2053/2445 [21:44<04:12,  1.55it/s]
em: 0.3501, f1: 0.4148, loss: 3.6279 ||:  85%|########4 | 2069/2445 [21:55<04:03,  1.54it/s]
em: 0.3504, f1: 0.4151, loss: 3.6255 ||:  85%|########5 | 2085/2445 [22:05<03:51,  1.55it/s]
em: 0.3507, f1: 0.4153, loss: 3.6245 ||:  86%|########5 | 2102/2445 [22:15<03:37,  1.58it/s]
em: 0.3508, f1: 0.4153, loss: 3.6270 ||:  87%|########6 | 2119/2445 [22:26<03:26,  1.58it/s]
em: 0.3507, f1: 0.4152, loss: 3.6280 ||:  87%|########7 | 2135/2445 [22:37<03:20,  1.54it/s]
em: 0.3508, f1: 0.4152, loss: 3.6278 ||:  88%|########7 | 2151/2445 [22:47<03:09,  1.55it/s]
em: 0.3512, f1: 0.4157, loss: 3.6274 ||:  89%|########8 | 2167/2445 [22:57<02:57,  1.57it/s]
em: 0.3512, f1: 0.4157, loss: 3.6269 ||:  89%|########9 | 2184/2445 [23:08<02:45,  1.58it/s]
em: 0.3508, f1: 0.4154, loss: 3.6250 ||:  90%|########9 | 2200/2445 [23:18<02:35,  1.57it/s]
em: 0.3509, f1: 0.4155, loss: 3.6238 ||:  91%|######### | 2216/2445 [23:28<02:26,  1.57it/s]
em: 0.3510, f1: 0.4157, loss: 3.6226 ||:  91%|#########1| 2232/2445 [23:39<02:16,  1.56it/s]
em: 0.3509, f1: 0.4156, loss: 3.6243 ||:  92%|#########1| 2248/2445 [23:49<02:07,  1.55it/s]
em: 0.3507, f1: 0.4154, loss: 3.6257 ||:  93%|#########2| 2264/2445 [24:00<01:56,  1.55it/s]
em: 0.3504, f1: 0.4152, loss: 3.6268 ||:  93%|#########3| 2280/2445 [24:10<01:46,  1.55it/s]
em: 0.3502, f1: 0.4151, loss: 3.6272 ||:  94%|#########3| 2296/2445 [24:20<01:35,  1.56it/s]
em: 0.3502, f1: 0.4151, loss: 3.6261 ||:  95%|#########4| 2312/2445 [24:30<01:25,  1.55it/s]
em: 0.3496, f1: 0.4147, loss: 3.6262 ||:  95%|#########5| 2328/2445 [24:41<01:15,  1.56it/s]
em: 0.3493, f1: 0.4144, loss: 3.6262 ||:  96%|#########5| 2344/2445 [24:51<01:05,  1.55it/s]
em: 0.3488, f1: 0.4141, loss: 3.6269 ||:  97%|#########6| 2360/2445 [25:02<00:55,  1.54it/s]
em: 0.3485, f1: 0.4139, loss: 3.6259 ||:  97%|#########7| 2376/2445 [25:12<00:44,  1.55it/s]
em: 0.3477, f1: 0.4133, loss: 3.6267 ||:  98%|#########7| 2393/2445 [25:22<00:32,  1.58it/s]
em: 0.3469, f1: 0.4125, loss: 3.6284 ||:  99%|#########8| 2410/2445 [25:33<00:22,  1.56it/s]
em: 0.3465, f1: 0.4122, loss: 3.6296 ||:  99%|#########9| 2427/2445 [25:44<00:11,  1.58it/s]
em: 0.3460, f1: 0.4119, loss: 3.6283 ||: 100%|#########9| 2444/2445 [25:54<00:00,  1.60it/s]
em: 0.3452, f1: 0.4112, loss: 3.6306 ||: : 2461it [26:06,  1.55it/s]                        
em: 0.3443, f1: 0.4104, loss: 3.6327 ||: : 2478it [26:16,  1.58it/s]

2019-05-10 08:42:55,643 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/596 [00:00<?, ?it/s]
em: 0.2957, f1: 0.3179, loss: 4278847.2596 ||:   4%|4         | 26/596 [00:10<03:39,  2.60it/s]
em: 0.2718, f1: 0.2976, loss: 4543270.3774 ||:   9%|8         | 52/596 [00:24<03:58,  2.28it/s]
em: 0.2725, f1: 0.3031, loss: 4473215.5786 ||:  12%|#1        | 70/596 [00:35<04:12,  2.08it/s]
em: 0.2778, f1: 0.3096, loss: 4402473.8331 ||:  15%|#5        | 91/596 [00:45<04:04,  2.06it/s]
em: 0.2804, f1: 0.3106, loss: 4570313.6613 ||:  19%|#8        | 112/596 [00:57<04:10,  1.93it/s]
em: 0.2634, f1: 0.2941, loss: 4721716.4694 ||:  23%|##2       | 137/596 [01:08<03:42,  2.06it/s]
em: 0.2559, f1: 0.2851, loss: 4760803.6408 ||:  27%|##7       | 162/596 [01:23<03:45,  1.93it/s]
em: 0.2497, f1: 0.2792, loss: 4783655.0498 ||:  31%|###       | 182/596 [01:33<03:35,  1.92it/s]
em: 0.2447, f1: 0.2733, loss: 4870690.8279 ||:  34%|###4      | 203/596 [01:43<03:20,  1.96it/s]
em: 0.2435, f1: 0.2725, loss: 4815849.4411 ||:  38%|###7      | 224/596 [01:55<03:12,  1.93it/s]
em: 0.2454, f1: 0.2743, loss: 4827936.4365 ||:  41%|####1     | 247/596 [02:05<02:53,  2.02it/s]
em: 0.2467, f1: 0.2756, loss: 4810186.4407 ||:  45%|####5     | 270/596 [02:19<02:52,  1.89it/s]
em: 0.2481, f1: 0.2766, loss: 4833049.1729 ||:  49%|####8     | 292/596 [02:29<02:35,  1.96it/s]
em: 0.2464, f1: 0.2739, loss: 4854698.6655 ||:  53%|#####2    | 314/596 [02:40<02:23,  1.97it/s]
em: 0.2456, f1: 0.2729, loss: 4840944.3270 ||:  56%|#####6    | 334/596 [02:51<02:17,  1.91it/s]
em: 0.2448, f1: 0.2717, loss: 4895539.4163 ||:  59%|#####9    | 353/596 [03:01<02:07,  1.90it/s]
em: 0.2505, f1: 0.2776, loss: 4830310.3206 ||:  62%|######2   | 372/596 [03:12<01:58,  1.89it/s]
em: 0.2524, f1: 0.2795, loss: 4822571.5403 ||:  66%|######5   | 391/596 [03:22<01:48,  1.89it/s]
em: 0.2520, f1: 0.2780, loss: 4834246.9496 ||:  69%|######8   | 411/596 [03:32<01:36,  1.91it/s]
em: 0.2512, f1: 0.2773, loss: 4820186.8410 ||:  72%|#######2  | 431/596 [03:42<01:25,  1.93it/s]
em: 0.2500, f1: 0.2764, loss: 4826775.0609 ||:  76%|#######5  | 451/596 [03:54<01:18,  1.85it/s]
em: 0.2441, f1: 0.2702, loss: 4889241.6930 ||:  80%|#######9  | 474/596 [04:04<01:02,  1.95it/s]
em: 0.2401, f1: 0.2661, loss: 4935866.3284 ||:  83%|########3 | 497/596 [04:15<00:49,  2.00it/s]
em: 0.2370, f1: 0.2630, loss: 4956037.2395 ||:  88%|########8 | 526/596 [04:25<00:31,  2.19it/s]
em: 0.2348, f1: 0.2606, loss: 4997748.8310 ||:  93%|#########3| 555/596 [04:37<00:18,  2.26it/s]
em: 0.2297, f1: 0.2555, loss: 5068966.5754 ||:  97%|#########7| 580/596 [04:50<00:07,  2.15it/s]
em: 0.2262, f1: 0.2525, loss: 5097917.7099 ||: : 600it [05:02,  1.98it/s]                       
em: 0.2254, f1: 0.2517, loss: 5101408.3286 ||: : 604it [05:05,  1.98it/s]

2019-05-10 08:48:01,441 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2019-05-10 08:48:01,442 - INFO - allennlp.training.tensorboard_writer - loss            |     3.633  |  5101408.329
2019-05-10 08:48:01,443 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  4561.000  |       N/A
2019-05-10 08:48:01,443 - INFO - allennlp.training.tensorboard_writer - em              |     0.344  |     0.225
2019-05-10 08:48:01,444 - INFO - allennlp.training.tensorboard_writer - f1              |     0.410  |     0.252
2019-05-10 08:48:01,444 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  6476.352  |       N/A
2019-05-10 08:48:43,800 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'out/rc_bert_simple_v2/best.th'.
